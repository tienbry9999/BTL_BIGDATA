25/03/13 09:38:52 INFO SparkContext: Running Spark version 2.4.3
25/03/13 09:38:52 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/13 09:38:52 INFO SparkContext: Submitted application: sparklyr
25/03/13 09:38:52 INFO SecurityManager: Changing view acls to: khanh
25/03/13 09:38:52 INFO SecurityManager: Changing modify acls to: khanh
25/03/13 09:38:52 INFO SecurityManager: Changing view acls groups to: 
25/03/13 09:38:52 INFO SecurityManager: Changing modify acls groups to: 
25/03/13 09:38:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(khanh); groups with view permissions: Set(); users  with modify permissions: Set(khanh); groups with modify permissions: Set()
25/03/13 09:38:52 INFO Utils: Successfully started service 'sparkDriver' on port 58212.
25/03/13 09:38:52 INFO SparkEnv: Registering MapOutputTracker
25/03/13 09:38:52 INFO SparkEnv: Registering BlockManagerMaster
25/03/13 09:38:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/13 09:38:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/03/13 09:38:52 INFO DiskBlockManager: Created local directory at C:\Users\khanh\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\blockmgr-317fe53c-87dc-428e-9fc9-a17a9ec6e748
25/03/13 09:38:52 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
25/03/13 09:38:52 INFO SparkEnv: Registering OutputCommitCoordinator
25/03/13 09:38:52 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/local]. Please check your configured local directories.
25/03/13 09:38:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/03/13 09:38:52 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
25/03/13 09:38:52 INFO SparkContext: Added JAR file:/C:/Users/khanh/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-2.4-2.11.jar at spark://127.0.0.1:58212/jars/sparklyr-2.4-2.11.jar with timestamp 1741833532847
25/03/13 09:38:52 INFO Executor: Starting executor ID driver on host localhost
25/03/13 09:38:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58253.
25/03/13 09:38:52 INFO NettyBlockTransferService: Server created on 127.0.0.1:58253
25/03/13 09:38:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/03/13 09:38:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 58253, None)
25/03/13 09:38:53 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:58253 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 58253, None)
25/03/13 09:38:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 58253, None)
25/03/13 09:38:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 58253, None)
25/03/13 09:38:53 INFO SharedState: loading hive config file: file:/C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/conf/hive-site.xml
25/03/13 09:38:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive').
25/03/13 09:38:53 INFO SharedState: Warehouse path is 'C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive'.
25/03/13 09:38:53 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
25/03/13 09:38:55 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
25/03/13 09:38:55 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
25/03/13 09:38:55 INFO ObjectStore: ObjectStore, initialize called
25/03/13 09:38:55 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/03/13 09:38:55 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/03/13 09:38:56 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/03/13 09:38:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
25/03/13 09:38:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
25/03/13 09:38:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
25/03/13 09:38:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
25/03/13 09:38:57 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/03/13 09:38:57 INFO ObjectStore: Initialized ObjectStore
25/03/13 09:38:57 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
25/03/13 09:38:57 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/03/13 09:38:57 INFO HiveMetaStore: Added admin role in metastore
25/03/13 09:38:57 INFO HiveMetaStore: Added public role in metastore
25/03/13 09:38:57 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_all_databases
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_all_databases	
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_functions: db=default pat=*
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
25/03/13 09:38:57 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
25/03/13 09:38:57 INFO SessionState: Created local directory: C:/Users/khanh/AppData/Local/Temp/faff3aff-6ddc-4133-af80-261bb9c33aff_resources
25/03/13 09:38:57 INFO SessionState: Created HDFS directory: C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/khanh/faff3aff-6ddc-4133-af80-261bb9c33aff
25/03/13 09:38:57 INFO SessionState: Created local directory: C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/faff3aff-6ddc-4133-af80-261bb9c33aff
25/03/13 09:38:57 INFO SessionState: Created HDFS directory: C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive/khanh/faff3aff-6ddc-4133-af80-261bb9c33aff/_tmp_space.db
25/03/13 09:38:57 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is C:/Users/khanh/AppData/Local/spark/spark-2.4.3-bin-hadoop2.7/tmp/hive
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_database: default
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_database: default	
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_database: global_temp
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/03/13 09:38:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_database: default
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_database: default	
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_database: default
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_database: default	
25/03/13 09:38:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/13 09:38:57 INFO audit: ugi=khanh	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/13 09:38:58 INFO CodeGenerator: Code generated in 137.7252 ms
25/03/13 09:42:19 INFO SparkContext: Invoking stop() from shutdown hook
25/03/13 09:42:19 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
25/03/13 09:42:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/03/13 09:42:19 INFO MemoryStore: MemoryStore cleared
25/03/13 09:42:19 INFO BlockManager: BlockManager stopped
25/03/13 09:42:19 INFO BlockManagerMaster: BlockManagerMaster stopped
25/03/13 09:42:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/03/13 09:42:19 INFO SparkContext: Successfully stopped SparkContext
25/03/13 09:42:19 INFO ShutdownHookManager: Shutdown hook called
25/03/13 09:42:19 INFO ShutdownHookManager: Deleting directory C:\Users\khanh\AppData\Local\Temp\spark-fe75d607-4f43-41f3-b09e-88e2c03f8773
25/03/13 09:42:19 INFO ShutdownHookManager: Deleting directory C:\Users\khanh\AppData\Local\spark\spark-2.4.3-bin-hadoop2.7\tmp\local\spark-5cb83c65-ade9-470f-9296-99a233a93850
25/03/14 09:40:15.500 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/conf/hive-site.xml
25/03/14 09:40:15.637 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.0
25/03/14 09:40:15.668 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/03/14 09:40:15.730 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/14 09:40:15.757 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/03/14 09:40:15.757 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/14 09:40:15.757 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/03/14 09:40:15.757 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/03/14 09:40:15.778 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/03/14 09:40:15.778 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/03/14 09:40:15.794 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/14 09:40:15.869 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Dotro
25/03/14 09:40:15.869 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Dotro
25/03/14 09:40:15.869 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/03/14 09:40:15.869 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/03/14 09:40:15.869 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Dotro); groups with view permissions: Set(); users  with modify permissions: Set(Dotro); groups with modify permissions: Set()
25/03/14 09:40:15.966 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 51175.
25/03/14 09:40:15.982 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/03/14 09:40:16.029 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/03/14 09:40:16.045 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/14 09:40:16.045 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/03/14 09:40:16.045 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/03/14 09:40:16.060 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\blockmgr-2b0c9b23-687d-4787-845c-4838f6b1d625
25/03/14 09:40:16.076 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/03/14 09:40:16.103 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/03/14 09:40:16.108 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/03/14 09:40:16.312 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/03/14 09:40:16.360 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Dotro/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.0-2.12.jar at spark://127.0.0.1:51175/jars/sparklyr-3.0-2.12.jar with timestamp 1741920015637
25/03/14 09:40:16.429 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/03/14 09:40:16.434 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/03/14 09:40:16.441 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:51175/jars/sparklyr-3.0-2.12.jar with timestamp 1741920015637
25/03/14 09:40:16.467 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51175 after 16 ms (0 ms spent in bootstraps)
25/03/14 09:40:16.498 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:51175/jars/sparklyr-3.0-2.12.jar to C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868\fetchFileTemp3638732792037676511.tmp
25/03/14 09:40:16.609 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/local/spark-989f5871-d0a3-4158-be42-ac3d1fead925/userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868/sparklyr-3.0-2.12.jar to class loader
25/03/14 09:40:16.624 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51223.
25/03/14 09:40:16.624 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:51223
25/03/14 09:40:16.624 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/03/14 09:40:16.624 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51223, None)
25/03/14 09:40:16.624 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51223 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 51223, None)
25/03/14 09:40:16.640 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51223, None)
25/03/14 09:40:16.640 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51223, None)
25/03/14 09:40:16.869 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/03/14 09:40:16.884 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/hive'.
25/03/14 09:40:20.051 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/03/14 09:40:20.146 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/conf/hive-site.xml
25/03/14 09:40:20.434 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/hive
25/03/14 09:40:20.620 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/03/14 09:40:20.621 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/03/14 09:40:20.621 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/03/14 09:40:20.654 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/03/14 09:40:20.753 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/03/14 09:40:20.753 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/03/14 09:40:21.649 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/03/14 09:40:22.749 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/03/14 09:40:22.752 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/03/14 09:40:22.800 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/03/14 09:40:22.800 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.10.101
25/03/14 09:40:22.837 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/03/14 09:40:22.999 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/03/14 09:40:23.001 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/03/14 09:40:23.041 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/03/14 09:40:23.130 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:23.132 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:23.152 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/03/14 09:40:23.152 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:40:23.153 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:40:23.941 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 180.9249 ms
25/03/14 09:40:24.053 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:40:24.071 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,005058 s
25/03/14 09:40:27.120 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.5251 ms
25/03/14 09:40:27.135 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:40:27.154 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:40:27.154 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:26)
25/03/14 09:40:27.154 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:40:27.154 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:40:27.173 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26), which has no missing parents
25/03/14 09:40:27.255 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.3 KiB, free 912.3 MiB)
25/03/14 09:40:27.304 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
25/03/14 09:40:27.304 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 912.3 MiB)
25/03/14 09:40:27.304 dag-scheduler-event-loop INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513
25/03/14 09:40:27.334 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:40:27.335 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/03/14 09:40:27.347 executor-heartbeater WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
25/03/14 09:40:27.393 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:40:27.403 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/03/14 09:40:27.630 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1362 bytes result sent to driver
25/03/14 09:40:27.636 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 264 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:40:27.640 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/03/14 09:40:27.646 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (collect at utils.scala:26) finished in 0,456 s
25/03/14 09:40:27.649 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:40:27.649 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/03/14 09:40:27.650 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: collect at utils.scala:26, took 0,499438 s
25/03/14 09:40:27.673 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.7912 ms
25/03/14 09:40:27.904 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:40:27.904 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:40:27.904 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:26)
25/03/14 09:40:27.904 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:40:27.904 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:40:27.914 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26), which has no missing parents
25/03/14 09:40:27.914 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 912.3 MiB)
25/03/14 09:40:27.914 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
25/03/14 09:40:27.914 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 912.3 MiB)
25/03/14 09:40:27.920 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/03/14 09:40:27.920 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:40:27.920 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
25/03/14 09:40:27.922 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:40:27.923 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/03/14 09:40:27.926 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1319 bytes result sent to driver
25/03/14 09:40:27.928 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:40:27.928 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/03/14 09:40:27.929 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (collect at utils.scala:26) finished in 0,015 s
25/03/14 09:40:27.929 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:40:27.929 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/03/14 09:40:27.929 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: collect at utils.scala:26, took 0,017722 s
25/03/14 09:40:28.339 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO DAGScheduler: Got job 3 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:26)
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26), which has no missing parents
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.3 KiB, free 912.3 MiB)
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
25/03/14 09:40:28.339 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 912.3 MiB)
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:40:28.339 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
25/03/14 09:40:28.354 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:40:28.354 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
25/03/14 09:40:28.354 Executor task launch worker for task 0.0 in stage 2.0 (TID 2) INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1319 bytes result sent to driver
25/03/14 09:40:28.354 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:40:28.354 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/03/14 09:40:28.354 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 2 (collect at utils.scala:26) finished in 0,015 s
25/03/14 09:40:28.354 dag-scheduler-event-loop INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:40:28.354 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
25/03/14 09:40:28.354 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 3 finished: collect at utils.scala:26, took 0,024577 s
25/03/14 09:40:29.223 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.9049 ms
25/03/14 09:40:29.240 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 12.9488 ms
25/03/14 09:40:29.322 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:26) as input to shuffle 0
25/03/14 09:40:29.323 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 4 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:40:29.323 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 3 (collect at utils.scala:26)
25/03/14 09:40:29.323 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:40:29.323 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:40:29.323 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:26), which has no missing parents
25/03/14 09:40:29.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.9 KiB, free 912.2 MiB)
25/03/14 09:40:29.356 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 912.2 MiB)
25/03/14 09:40:29.356 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51223 (size: 8.1 KiB, free: 912.3 MiB)
25/03/14 09:40:29.356 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
25/03/14 09:40:29.356 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:40:29.356 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
25/03/14 09:40:29.511 dispatcher-event-loop-5 WARN TaskSetManager: Stage 3 contains a task of very large size (17779 KiB). The maximum recommended task size is 1000 KiB.
25/03/14 09:40:29.511 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 18206290 bytes) taskResourceAssignments Map()
25/03/14 09:40:29.511 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
25/03/14 09:40:29.529 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 912.3 MiB)
25/03/14 09:40:29.534 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 912.3 MiB)
25/03/14 09:40:29.536 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 912.3 MiB)
25/03/14 09:40:30.113 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 8.0 MiB, free 904.3 MiB)
25/03/14 09:40:30.114 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:51223 (size: 8.0 MiB, free: 904.3 MiB)
25/03/14 09:40:30.194 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 67.8662 ms
25/03/14 09:40:30.203 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO CodeGenerator: Code generated in 19.6573 ms
25/03/14 09:40:30.270 Executor task launch worker for task 0.0 in stage 3.0 (TID 3) INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1990 bytes result sent to driver
25/03/14 09:40:30.270 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 914 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:40:30.270 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
25/03/14 09:40:30.270 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:26) finished in 0,947 s
25/03/14 09:40:30.270 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 09:40:30.270 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 09:40:30.270 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 09:40:30.270 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 09:40:30.306 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.0693 ms
25/03/14 09:40:30.341 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:40:30.343 dag-scheduler-event-loop INFO DAGScheduler: Got job 5 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:40:30.343 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:26)
25/03/14 09:40:30.343 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
25/03/14 09:40:30.343 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:40:30.344 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at collect at utils.scala:26), which has no missing parents
25/03/14 09:40:30.354 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.1 KiB, free 904.3 MiB)
25/03/14 09:40:30.354 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 904.3 MiB)
25/03/14 09:40:30.354 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51223 (size: 5.5 KiB, free: 904.3 MiB)
25/03/14 09:40:30.354 dag-scheduler-event-loop INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513
25/03/14 09:40:30.354 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:40:30.354 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
25/03/14 09:40:30.354 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 09:40:30.354 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
25/03/14 09:40:30.393 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 09:40:30.394 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
25/03/14 09:40:30.405 Executor task launch worker for task 0.0 in stage 5.0 (TID 4) INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 2570 bytes result sent to driver
25/03/14 09:40:30.405 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 51 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:40:30.405 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/03/14 09:40:30.405 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 5 (collect at utils.scala:26) finished in 0,053 s
25/03/14 09:40:30.405 dag-scheduler-event-loop INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:40:30.405 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
25/03/14 09:40:30.405 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 5 finished: collect at utils.scala:26, took 0,070824 s
25/03/14 09:40:30.422 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.0782 ms
25/03/14 09:40:52.188 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:52.188 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:52.205 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:52.205 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:52.220 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:40:52.220 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:40:52.271 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 27.9073 ms
25/03/14 09:40:52.308 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.3717 ms
25/03/14 09:40:52.319 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.9943 ms
25/03/14 09:40:52.365 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:52.365 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:52.367 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:52.367 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:52.368 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:40:52.368 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:40:52.439 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:52.439 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:52.440 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:40:52.440 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:40:52.440 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:40:52.440 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:43:14.102 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:43:14.103 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:43:14.104 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:43:14.104 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:43:14.106 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:43:14.106 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:43:14.186 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:43:14.188 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 2 output partitions
25/03/14 09:43:14.188 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:26)
25/03/14 09:43:14.188 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:43:14.188 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:43:14.188 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51223 in memory (size: 5.5 KiB, free: 904.3 MiB)
25/03/14 09:43:14.189 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at collect at utils.scala:26), which has no missing parents
25/03/14 09:43:14.192 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.1 KiB, free 904.3 MiB)
25/03/14 09:43:14.192 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51223 in memory (size: 8.1 KiB, free: 904.3 MiB)
25/03/14 09:43:14.193 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 904.3 MiB)
25/03/14 09:43:14.193 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:14.193 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
25/03/14 09:43:14.195 dag-scheduler-event-loop INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1))
25/03/14 09:43:14.195 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks resource profile 0
25/03/14 09:43:14.195 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4657 bytes) taskResourceAssignments Map()
25/03/14 09:43:14.196 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 6) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
25/03/14 09:43:14.197 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Running task 0.0 in stage 6.0 (TID 5)
25/03/14 09:43:14.197 Executor task launch worker for task 1.0 in stage 6.0 (TID 6) INFO Executor: Running task 1.0 in stage 6.0 (TID 6)
25/03/14 09:43:14.201 Executor task launch worker for task 1.0 in stage 6.0 (TID 6) INFO Executor: Finished task 1.0 in stage 6.0 (TID 6). 1382 bytes result sent to driver
25/03/14 09:43:14.201 Executor task launch worker for task 0.0 in stage 6.0 (TID 5) INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 1342 bytes result sent to driver
25/03/14 09:43:14.202 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 6) in 6 ms on 127.0.0.1 (executor driver) (1/2)
25/03/14 09:43:14.203 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 8 ms on 127.0.0.1 (executor driver) (2/2)
25/03/14 09:43:14.203 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
25/03/14 09:43:14.203 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 6 (collect at utils.scala:26) finished in 0,014 s
25/03/14 09:43:14.203 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:43:14.204 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
25/03/14 09:43:14.204 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0,017109 s
25/03/14 09:43:14.210 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 4.8449 ms
25/03/14 09:43:15.125 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:15.270 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[27] at collect at utils.scala:26), which has no missing parents
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KiB, free 904.3 MiB)
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 904.3 MiB)
25/03/14 09:43:15.270 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[27] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:43:15.270 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/03/14 09:43:15.279 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:43:15.279 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
25/03/14 09:43:15.279 Executor task launch worker for task 0.0 in stage 7.0 (TID 7) INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1276 bytes result sent to driver
25/03/14 09:43:15.279 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 0 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:43:15.279 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/03/14 09:43:15.279 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0,009 s
25/03/14 09:43:15.279 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:43:15.279 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/03/14 09:43:15.279 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,012493 s
25/03/14 09:43:15.415 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:43:15.415 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:43:15.415 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
25/03/14 09:43:15.416 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:43:15.416 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:43:15.416 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[29] at collect at utils.scala:26), which has no missing parents
25/03/14 09:43:15.418 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.3 KiB, free 904.3 MiB)
25/03/14 09:43:15.421 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 904.3 MiB)
25/03/14 09:43:15.422 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:15.422 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
25/03/14 09:43:15.423 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:43:15.423 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/03/14 09:43:15.423 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:43:15.423 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
25/03/14 09:43:15.423 Executor task launch worker for task 0.0 in stage 8.0 (TID 8) INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1276 bytes result sent to driver
25/03/14 09:43:15.423 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 0 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:43:15.423 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/03/14 09:43:15.423 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0,006 s
25/03/14 09:43:15.423 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:43:15.423 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/03/14 09:43:15.423 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0,015084 s
25/03/14 09:43:15.504 nioEventLoopGroup-2-2 WARN CacheManager: Asked to cache already cached data.
25/03/14 09:43:15.587 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26), which has no missing parents
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.3 KiB, free 904.3 MiB)
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 904.3 MiB)
25/03/14 09:43:15.587 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[31] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/03/14 09:43:15.587 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:43:15.587 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
25/03/14 09:43:15.587 Executor task launch worker for task 0.0 in stage 9.0 (TID 9) INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1276 bytes result sent to driver
25/03/14 09:43:15.587 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 0 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:43:15.587 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0,000 s
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:43:15.587 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/03/14 09:43:15.587 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: collect at utils.scala:26, took 0,010832 s
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 39 (collect at utils.scala:26) as input to shuffle 1
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 10 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at utils.scala:26)
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[39] at collect at utils.scala:26), which has no missing parents
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 18.9 KiB, free 904.3 MiB)
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 904.3 MiB)
25/03/14 09:43:15.784 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51223 (size: 8.2 KiB, free: 904.3 MiB)
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[39] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:43:15.784 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/03/14 09:43:15.838 dispatcher-event-loop-1 WARN TaskSetManager: Stage 10 contains a task of very large size (17779 KiB). The maximum recommended task size is 1000 KiB.
25/03/14 09:43:15.838 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 18206290 bytes) taskResourceAssignments Map()
25/03/14 09:43:15.839 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
25/03/14 09:43:16.068 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:16.068 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:16.083 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 904.3 MiB)
25/03/14 09:43:16.103 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 8.0 MiB, free 896.3 MiB)
25/03/14 09:43:16.103 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:51223 (size: 8.0 MiB, free: 896.3 MiB)
25/03/14 09:43:16.125 Executor task launch worker for task 0.0 in stage 10.0 (TID 10) INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2033 bytes result sent to driver
25/03/14 09:43:16.125 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 326 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:43:16.125 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/03/14 09:43:16.126 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:26) finished in 0,342 s
25/03/14 09:43:16.126 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 09:43:16.126 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 09:43:16.126 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 09:43:16.126 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 09:43:16.138 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:43:16.139 dag-scheduler-event-loop INFO DAGScheduler: Got job 11 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:43:16.139 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:26)
25/03/14 09:43:16.139 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
25/03/14 09:43:16.139 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:43:16.141 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[42] at collect at utils.scala:26), which has no missing parents
25/03/14 09:43:16.142 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 11.1 KiB, free 896.3 MiB)
25/03/14 09:43:16.143 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 896.3 MiB)
25/03/14 09:43:16.144 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51223 (size: 5.5 KiB, free: 896.3 MiB)
25/03/14 09:43:16.144 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
25/03/14 09:43:16.144 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[42] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:43:16.144 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
25/03/14 09:43:16.145 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 11) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 09:43:16.145 Executor task launch worker for task 0.0 in stage 12.0 (TID 11) INFO Executor: Running task 0.0 in stage 12.0 (TID 11)
25/03/14 09:43:16.147 Executor task launch worker for task 0.0 in stage 12.0 (TID 11) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 09:43:16.148 Executor task launch worker for task 0.0 in stage 12.0 (TID 11) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 09:43:16.149 Executor task launch worker for task 0.0 in stage 12.0 (TID 11) INFO Executor: Finished task 0.0 in stage 12.0 (TID 11). 2570 bytes result sent to driver
25/03/14 09:43:16.149 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 11) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:43:16.149 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/03/14 09:43:16.150 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 12 (collect at utils.scala:26) finished in 0,009 s
25/03/14 09:43:16.150 dag-scheduler-event-loop INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:43:16.150 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
25/03/14 09:43:16.150 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 11 finished: collect at utils.scala:26, took 0,011501 s
25/03/14 09:43:36.843 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:43:36.844 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:43:36.846 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:43:36.846 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:43:36.847 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:43:36.847 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:44:56.017 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:44:56.017 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:44:56.028 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:44:56.028 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:44:56.028 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:44:56.028 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 09:44:56.079 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:44:56.080 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (collect at utils.scala:26) with 3 output partitions
25/03/14 09:44:56.080 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:26)
25/03/14 09:44:56.080 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:44:56.081 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:44:56.081 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:26), which has no missing parents
25/03/14 09:44:56.083 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.1 KiB, free 896.3 MiB)
25/03/14 09:44:56.085 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 896.3 MiB)
25/03/14 09:44:56.086 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 896.3 MiB)
25/03/14 09:44:56.086 dag-scheduler-event-loop INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
25/03/14 09:44:56.087 dag-scheduler-event-loop INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 13 (MapPartitionsRDD[45] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2))
25/03/14 09:44:56.087 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 13.0 with 3 tasks resource profile 0
25/03/14 09:44:56.087 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4657 bytes) taskResourceAssignments Map()
25/03/14 09:44:56.088 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 13) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
25/03/14 09:44:56.088 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 14) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4697 bytes) taskResourceAssignments Map()
25/03/14 09:44:56.090 Executor task launch worker for task 2.0 in stage 13.0 (TID 14) INFO Executor: Running task 2.0 in stage 13.0 (TID 14)
25/03/14 09:44:56.090 Executor task launch worker for task 1.0 in stage 13.0 (TID 13) INFO Executor: Running task 1.0 in stage 13.0 (TID 13)
25/03/14 09:44:56.090 Executor task launch worker for task 0.0 in stage 13.0 (TID 12) INFO Executor: Running task 0.0 in stage 13.0 (TID 12)
25/03/14 09:44:56.092 Executor task launch worker for task 0.0 in stage 13.0 (TID 12) INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1299 bytes result sent to driver
25/03/14 09:44:56.092 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 5 ms on 127.0.0.1 (executor driver) (1/3)
25/03/14 09:44:56.092 Executor task launch worker for task 1.0 in stage 13.0 (TID 13) INFO Executor: Finished task 1.0 in stage 13.0 (TID 13). 1339 bytes result sent to driver
25/03/14 09:44:56.092 Executor task launch worker for task 2.0 in stage 13.0 (TID 14) INFO Executor: Finished task 2.0 in stage 13.0 (TID 14). 1339 bytes result sent to driver
25/03/14 09:44:56.093 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 13) in 6 ms on 127.0.0.1 (executor driver) (2/3)
25/03/14 09:44:56.093 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 14) in 5 ms on 127.0.0.1 (executor driver) (3/3)
25/03/14 09:44:56.093 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
25/03/14 09:44:56.093 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 13 (collect at utils.scala:26) finished in 0,011 s
25/03/14 09:44:56.094 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:44:56.094 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
25/03/14 09:44:56.094 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: collect at utils.scala:26, took 0,014103 s
25/03/14 09:44:56.588 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 896.3 MiB)
25/03/14 09:44:56.588 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51223 in memory (size: 8.2 KiB, free: 896.3 MiB)
25/03/14 09:44:56.596 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51223 in memory (size: 5.5 KiB, free: 896.3 MiB)
25/03/14 09:44:57.002 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Got job 13 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:26)
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[48] at collect at utils.scala:26), which has no missing parents
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KiB, free 896.3 MiB)
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 896.3 MiB)
25/03/14 09:44:57.003 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 896.3 MiB)
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[48] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/03/14 09:44:57.003 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:44:57.003 Executor task launch worker for task 0.0 in stage 14.0 (TID 15) INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
25/03/14 09:44:57.003 Executor task launch worker for task 0.0 in stage 14.0 (TID 15) INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1319 bytes result sent to driver
25/03/14 09:44:57.003 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 0 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:44:57.003 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (collect at utils.scala:26) finished in 0,000 s
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:44:57.003 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/03/14 09:44:57.003 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 13 finished: collect at utils.scala:26, took 0,011021 s
25/03/14 09:44:57.144 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:44:57.144 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:44:57.144 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:26)
25/03/14 09:44:57.144 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:44:57.145 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:44:57.145 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:26), which has no missing parents
25/03/14 09:44:57.146 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.3 KiB, free 896.3 MiB)
25/03/14 09:44:57.147 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 896.3 MiB)
25/03/14 09:44:57.148 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 896.3 MiB)
25/03/14 09:44:57.148 dag-scheduler-event-loop INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
25/03/14 09:44:57.149 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[50] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:44:57.149 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
25/03/14 09:44:57.150 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:44:57.151 Executor task launch worker for task 0.0 in stage 15.0 (TID 16) INFO Executor: Running task 0.0 in stage 15.0 (TID 16)
25/03/14 09:44:57.154 Executor task launch worker for task 0.0 in stage 15.0 (TID 16) INFO Executor: Finished task 0.0 in stage 15.0 (TID 16). 1276 bytes result sent to driver
25/03/14 09:44:57.154 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:44:57.154 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/03/14 09:44:57.154 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 15 (collect at utils.scala:26) finished in 0,009 s
25/03/14 09:44:57.154 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:44:57.154 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
25/03/14 09:44:57.154 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collect at utils.scala:26, took 0,010596 s
25/03/14 09:44:57.223 nioEventLoopGroup-2-2 WARN CacheManager: Asked to cache already cached data.
25/03/14 09:44:57.302 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:26)
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[52] at collect at utils.scala:26), which has no missing parents
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.3 KiB, free 896.3 MiB)
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 896.3 MiB)
25/03/14 09:44:57.302 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51223 (size: 3.7 KiB, free: 896.3 MiB)
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[52] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
25/03/14 09:44:57.302 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 09:44:57.302 Executor task launch worker for task 0.0 in stage 16.0 (TID 17) INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
25/03/14 09:44:57.302 Executor task launch worker for task 0.0 in stage 16.0 (TID 17) INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1276 bytes result sent to driver
25/03/14 09:44:57.302 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 0 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:44:57.302 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 16 (collect at utils.scala:26) finished in 0,000 s
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:44:57.302 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
25/03/14 09:44:57.302 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0,008833 s
25/03/14 09:44:57.490 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:26) as input to shuffle 2
25/03/14 09:44:57.490 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 16 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:44:57.490 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 17 (collect at utils.scala:26)
25/03/14 09:44:57.490 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 09:44:57.490 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:44:57.491 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:26), which has no missing parents
25/03/14 09:44:57.502 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 18.9 KiB, free 896.3 MiB)
25/03/14 09:44:57.504 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 896.3 MiB)
25/03/14 09:44:57.504 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51223 (size: 8.2 KiB, free: 896.3 MiB)
25/03/14 09:44:57.504 dag-scheduler-event-loop INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
25/03/14 09:44:57.505 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:44:57.505 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/03/14 09:44:57.535 dispatcher-event-loop-4 WARN TaskSetManager: Stage 17 contains a task of very large size (17779 KiB). The maximum recommended task size is 1000 KiB.
25/03/14 09:44:57.535 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 18206290 bytes) taskResourceAssignments Map()
25/03/14 09:44:57.535 Executor task launch worker for task 0.0 in stage 17.0 (TID 18) INFO Executor: Running task 0.0 in stage 17.0 (TID 18)
25/03/14 09:44:57.734 Executor task launch worker for task 0.0 in stage 17.0 (TID 18) INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 8.0 MiB, free 888.3 MiB)
25/03/14 09:44:57.734 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:51223 (size: 8.0 MiB, free: 888.4 MiB)
25/03/14 09:44:57.750 Executor task launch worker for task 0.0 in stage 17.0 (TID 18) INFO Executor: Finished task 0.0 in stage 17.0 (TID 18). 1990 bytes result sent to driver
25/03/14 09:44:57.750 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 245 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:44:57.750 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/03/14 09:44:57.750 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:26) finished in 0,259 s
25/03/14 09:44:57.750 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 09:44:57.750 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 09:44:57.750 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 09:44:57.750 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 09:44:57.754 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 09:44:57.766 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (collect at utils.scala:26) with 1 output partitions
25/03/14 09:44:57.766 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:26)
25/03/14 09:44:57.766 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
25/03/14 09:44:57.766 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 09:44:57.766 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[63] at collect at utils.scala:26), which has no missing parents
25/03/14 09:44:57.768 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.1 KiB, free 888.3 MiB)
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 888.3 MiB)
25/03/14 09:44:57.770 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51223 (size: 5.5 KiB, free: 888.3 MiB)
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[63] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/03/14 09:44:57.770 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 09:44:57.770 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
25/03/14 09:44:57.770 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 09:44:57.770 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 09:44:57.770 Executor task launch worker for task 0.0 in stage 19.0 (TID 19) INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2570 bytes result sent to driver
25/03/14 09:44:57.770 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 0 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 09:44:57.770 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 19 (collect at utils.scala:26) finished in 0,004 s
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 09:44:57.770 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
25/03/14 09:44:57.770 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: collect at utils.scala:26, took 0,013728 s
25/03/14 09:45:18.750 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:45:18.751 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:45:18.753 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 09:45:18.753 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 09:45:18.753 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 09:45:18.753 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 10:10:19.307 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:51223 in memory (size: 5.5 KiB, free: 888.4 MiB)
25/03/14 10:10:19.314 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 888.4 MiB)
25/03/14 10:10:19.317 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 888.4 MiB)
25/03/14 10:10:19.325 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:51223 in memory (size: 3.7 KiB, free: 888.4 MiB)
25/03/14 10:10:19.328 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:51223 in memory (size: 8.2 KiB, free: 888.4 MiB)
25/03/14 10:33:11.294 shutdown-hook-0 INFO SparkContext: Invoking stop() from shutdown hook
25/03/14 10:33:11.463 shutdown-hook-0 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
25/03/14 10:33:11.528 dispatcher-event-loop-1 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/03/14 10:33:11.627 shutdown-hook-0 INFO MemoryStore: MemoryStore cleared
25/03/14 10:33:11.627 shutdown-hook-0 INFO BlockManager: BlockManager stopped
25/03/14 10:33:11.644 shutdown-hook-0 INFO BlockManagerMaster: BlockManagerMaster stopped
25/03/14 10:33:11.644 dispatcher-event-loop-6 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/03/14 10:33:11.661 shutdown-hook-0 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868
java.io.IOException: Failed to delete: C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:108)
	at org.apache.spark.SparkContext.$anonfun$stop$23(SparkContext.scala:2140)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2140)
	at org.apache.spark.SparkContext.$anonfun$new$35(SparkContext.scala:660)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
25/03/14 10:33:11.685 shutdown-hook-0 INFO SparkContext: Successfully stopped SparkContext
25/03/14 10:33:11.685 shutdown-hook-0 INFO ShutdownHookManager: Shutdown hook called
25/03/14 10:33:11.687 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925
25/03/14 10:33:11.689 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925
java.io.IOException: Failed to delete: C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
25/03/14 10:33:11.690 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Dotro\AppData\Local\Temp\spark-0677dfcd-704b-4a12-b6ae-6f802102d563
25/03/14 10:33:11.691 shutdown-hook-0 INFO ShutdownHookManager: Deleting directory C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868
25/03/14 10:33:11.694 shutdown-hook-0 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868
java.io.IOException: Failed to delete: C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-989f5871-d0a3-4158-be42-ac3d1fead925\userFiles-08b7d1f3-ea72-4ea8-af13-85a6c511f868\sparklyr-3.0-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1206)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
25/03/14 11:10:57.463 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/conf/hive-site.xml
25/03/14 11:10:57.649 nioEventLoopGroup-2-2 INFO SparkContext: Running Spark version 3.3.0
25/03/14 11:10:57.674 nioEventLoopGroup-2-2 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/03/14 11:10:57.742 nioEventLoopGroup-2-2 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/14 11:10:57.767 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/03/14 11:10:57.767 nioEventLoopGroup-2-2 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/14 11:10:57.767 nioEventLoopGroup-2-2 INFO ResourceUtils: ==============================================================
25/03/14 11:10:57.768 nioEventLoopGroup-2-2 INFO SparkContext: Submitted application: sparklyr
25/03/14 11:10:57.795 nioEventLoopGroup-2-2 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/03/14 11:10:57.806 nioEventLoopGroup-2-2 INFO ResourceProfile: Limiting resource is cpu
25/03/14 11:10:57.806 nioEventLoopGroup-2-2 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/14 11:10:57.925 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls to: Dotro
25/03/14 11:10:57.925 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls to: Dotro
25/03/14 11:10:57.926 nioEventLoopGroup-2-2 INFO SecurityManager: Changing view acls groups to: 
25/03/14 11:10:57.926 nioEventLoopGroup-2-2 INFO SecurityManager: Changing modify acls groups to: 
25/03/14 11:10:57.927 nioEventLoopGroup-2-2 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Dotro); groups with view permissions: Set(); users  with modify permissions: Set(Dotro); groups with modify permissions: Set()
25/03/14 11:10:58.028 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'sparkDriver' on port 53598.
25/03/14 11:10:58.056 nioEventLoopGroup-2-2 INFO SparkEnv: Registering MapOutputTracker
25/03/14 11:10:58.094 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMaster
25/03/14 11:10:58.117 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/14 11:10:58.118 nioEventLoopGroup-2-2 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/03/14 11:10:58.121 nioEventLoopGroup-2-2 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/03/14 11:10:58.153 nioEventLoopGroup-2-2 INFO DiskBlockManager: Created local directory at C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\blockmgr-d6a25445-130d-49ed-b148-713ef5611147
25/03/14 11:10:58.179 nioEventLoopGroup-2-2 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
25/03/14 11:10:58.198 nioEventLoopGroup-2-2 INFO SparkEnv: Registering OutputCommitCoordinator
25/03/14 11:10:58.201 nioEventLoopGroup-2-2 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/local]. Please check your configured local directories.
25/03/14 11:10:58.434 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/03/14 11:10:58.474 nioEventLoopGroup-2-2 INFO SparkContext: Added JAR file:/C:/Users/Dotro/AppData/Local/R/win-library/4.4/sparklyr/java/sparklyr-3.0-2.12.jar at spark://127.0.0.1:53598/jars/sparklyr-3.0-2.12.jar with timestamp 1741925457641
25/03/14 11:10:58.554 nioEventLoopGroup-2-2 INFO Executor: Starting executor ID driver on host 127.0.0.1
25/03/14 11:10:58.562 nioEventLoopGroup-2-2 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/03/14 11:10:58.572 nioEventLoopGroup-2-2 INFO Executor: Fetching spark://127.0.0.1:53598/jars/sparklyr-3.0-2.12.jar with timestamp 1741925457641
25/03/14 11:10:58.616 nioEventLoopGroup-2-2 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53598 after 24 ms (0 ms spent in bootstraps)
25/03/14 11:10:58.620 nioEventLoopGroup-2-2 INFO Utils: Fetching spark://127.0.0.1:53598/jars/sparklyr-3.0-2.12.jar to C:\Users\Dotro\AppData\Local\spark\spark-3.3.0-bin-hadoop3\tmp\local\spark-09cbd6eb-6856-4721-a1fa-168834d77aad\userFiles-caf320b2-f0a1-4d59-956e-834bd326fe49\fetchFileTemp3301755331853463936.tmp
25/03/14 11:10:58.727 nioEventLoopGroup-2-2 INFO Executor: Adding file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/local/spark-09cbd6eb-6856-4721-a1fa-168834d77aad/userFiles-caf320b2-f0a1-4d59-956e-834bd326fe49/sparklyr-3.0-2.12.jar to class loader
25/03/14 11:10:58.741 nioEventLoopGroup-2-2 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53646.
25/03/14 11:10:58.741 nioEventLoopGroup-2-2 INFO NettyBlockTransferService: Server created on 127.0.0.1:53646
25/03/14 11:10:58.745 nioEventLoopGroup-2-2 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/03/14 11:10:58.753 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53646, None)
25/03/14 11:10:58.756 dispatcher-BlockManagerMaster INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53646 with 912.3 MiB RAM, BlockManagerId(driver, 127.0.0.1, 53646, None)
25/03/14 11:10:58.758 nioEventLoopGroup-2-2 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53646, None)
25/03/14 11:10:58.761 nioEventLoopGroup-2-2 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53646, None)
25/03/14 11:10:59.064 nioEventLoopGroup-2-2 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/hive') to the value of spark.sql.warehouse.dir.
25/03/14 11:10:59.072 nioEventLoopGroup-2-2 INFO SharedState: Warehouse path is 'file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/hive'.
25/03/14 11:11:02.252 nioEventLoopGroup-2-2 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
25/03/14 11:11:02.349 nioEventLoopGroup-2-2 INFO HiveConf: Found configuration file file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/conf/hive-site.xml
25/03/14 11:11:02.619 nioEventLoopGroup-2-2 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.9) is file:/C:/Users/Dotro/AppData/Local/spark/spark-3.3.0-bin-hadoop3/tmp/hive
25/03/14 11:11:02.948 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
25/03/14 11:11:02.949 nioEventLoopGroup-2-2 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
25/03/14 11:11:02.949 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
25/03/14 11:11:02.984 nioEventLoopGroup-2-2 INFO ObjectStore: ObjectStore, initialize called
25/03/14 11:11:03.122 nioEventLoopGroup-2-2 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
25/03/14 11:11:03.123 nioEventLoopGroup-2-2 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
25/03/14 11:11:04.092 nioEventLoopGroup-2-2 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
25/03/14 11:11:05.198 nioEventLoopGroup-2-2 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
25/03/14 11:11:05.201 nioEventLoopGroup-2-2 INFO ObjectStore: Initialized ObjectStore
25/03/14 11:11:05.264 nioEventLoopGroup-2-2 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
25/03/14 11:11:05.264 nioEventLoopGroup-2-2 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@192.168.10.101
25/03/14 11:11:05.291 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
25/03/14 11:11:05.440 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added admin role in metastore
25/03/14 11:11:05.442 nioEventLoopGroup-2-2 INFO HiveMetaStore: Added public role in metastore
25/03/14 11:11:05.479 nioEventLoopGroup-2-2 INFO HiveMetaStore: No user is added in admin role, since config is empty
25/03/14 11:11:05.591 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:05.593 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:05.611 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: global_temp
25/03/14 11:11:05.612 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: global_temp	
25/03/14 11:11:05.612 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
25/03/14 11:11:05.613 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:05.613 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:05.615 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:05.616 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:05.617 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:11:05.617 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:11:06.322 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 170.4121 ms
25/03/14 11:11:06.452 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:11:06.457 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 0 finished: collect at utils.scala:26, took 0,004124 s
25/03/14 11:11:06.783 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 31 ms to list leaf files for 1 paths.
25/03/14 11:11:06.839 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/03/14 11:11:07.020 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:11:07.021 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#14, None)) > 0)
25/03/14 11:11:07.023 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:11:07.063 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 11.4369 ms
25/03/14 11:11:07.112 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 358.6 KiB, free 911.9 MiB)
25/03/14 11:11:07.179 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 911.9 MiB)
25/03/14 11:11:07.181 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 912.3 MiB)
25/03/14 11:11:07.184 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:11:07.193 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:11:07.244 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:11:07.256 dag-scheduler-event-loop INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/14 11:11:07.256 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:11:07.256 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:11:07.257 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:07.261 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:11:07.292 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KiB, free 911.9 MiB)
25/03/14 11:11:07.294 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 911.9 MiB)
25/03/14 11:11:07.295 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53646 (size: 5.9 KiB, free: 912.3 MiB)
25/03/14 11:11:07.296 dag-scheduler-event-loop INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:07.307 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:11:07.308 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/03/14 11:11:07.349 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:11:07.363 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/03/14 11:11:07.574 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:11:07.646 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO CodeGenerator: Code generated in 68.4066 ms
25/03/14 11:11:07.700 Executor task launch worker for task 0.0 in stage 0.0 (TID 0) INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1587 bytes result sent to driver
25/03/14 11:11:07.705 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 362 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:11:07.706 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/03/14 11:11:07.713 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0,439 s
25/03/14 11:11:07.716 dag-scheduler-event-loop INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:11:07.717 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/03/14 11:11:07.717 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0,472989 s
25/03/14 11:11:07.735 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 5.8695 ms
25/03/14 11:11:07.779 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:11:07.779 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:11:07.779 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:11:07.784 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 358.6 KiB, free 911.5 MiB)
25/03/14 11:11:07.792 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 911.5 MiB)
25/03/14 11:11:07.794 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 912.2 MiB)
25/03/14 11:11:07.794 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:11:07.795 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:11:07.833 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:11:07.834 dag-scheduler-event-loop INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/03/14 11:11:07.835 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:11:07.835 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:11:07.835 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:07.836 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:11:07.880 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.2 KiB, free 911.5 MiB)
25/03/14 11:11:07.882 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.9 KiB, free 911.5 MiB)
25/03/14 11:11:07.883 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53646 (size: 11.9 KiB, free: 912.2 MiB)
25/03/14 11:11:07.883 dag-scheduler-event-loop INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:07.883 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:11:07.884 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
25/03/14 11:11:07.885 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:11:07.885 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:11:07.886 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:11:07.886 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:11:07.886 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
25/03/14 11:11:07.887 Executor task launch worker for task 3.0 in stage 1.0 (TID 4) INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
25/03/14 11:11:07.887 Executor task launch worker for task 1.0 in stage 1.0 (TID 2) INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
25/03/14 11:11:07.887 Executor task launch worker for task 2.0 in stage 1.0 (TID 3) INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
25/03/14 11:11:07.955 Executor task launch worker for task 3.0 in stage 1.0 (TID 4) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:11:07.955 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:11:07.955 Executor task launch worker for task 1.0 in stage 1.0 (TID 2) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:11:07.955 Executor task launch worker for task 2.0 in stage 1.0 (TID 3) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:11:08.207 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 912.2 MiB)
25/03/14 11:11:08.216 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53646 in memory (size: 5.9 KiB, free: 912.3 MiB)
25/03/14 11:11:08.218 Executor task launch worker for task 3.0 in stage 1.0 (TID 4) INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1677 bytes result sent to driver
25/03/14 11:11:08.218 Executor task launch worker for task 2.0 in stage 1.0 (TID 3) INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1677 bytes result sent to driver
25/03/14 11:11:08.219 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 333 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:11:08.221 Executor task launch worker for task 1.0 in stage 1.0 (TID 2) INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1634 bytes result sent to driver
25/03/14 11:11:08.221 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 336 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:11:08.223 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 337 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:11:08.237 Executor task launch worker for task 0.0 in stage 1.0 (TID 1) INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1634 bytes result sent to driver
25/03/14 11:11:08.238 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 354 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:11:08.238 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/03/14 11:11:08.238 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0,401 s
25/03/14 11:11:08.240 dag-scheduler-event-loop INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:11:08.240 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/03/14 11:11:08.240 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0,405786 s
25/03/14 11:11:08.287 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:08.287 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:08.289 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:08.289 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:08.290 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:11:08.290 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:11:08.441 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:11:08.442 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:11:08.442 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<Order ID: int, Product: string, Quantity Ordered: int, Price Each: double, Order Date: string ... 1 more field>
25/03/14 11:11:08.625 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.8317 ms
25/03/14 11:11:08.640 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 10.4552 ms
25/03/14 11:11:08.646 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 358.5 KiB, free 911.5 MiB)
25/03/14 11:11:08.656 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 911.5 MiB)
25/03/14 11:11:08.657 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53646 (size: 34.8 KiB, free: 912.2 MiB)
25/03/14 11:11:08.658 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 4 from sql at NativeMethodAccessorImpl.java:0
25/03/14 11:11:08.665 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:11:08.721 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 22 (sql at NativeMethodAccessorImpl.java:0) as input to shuffle 0
25/03/14 11:11:08.727 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 3 (sql at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/03/14 11:11:08.727 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 2 (sql at NativeMethodAccessorImpl.java:0)
25/03/14 11:11:08.727 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:11:08.730 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:08.732 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[22] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:11:08.757 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 24.4 KiB, free 911.5 MiB)
25/03/14 11:11:08.761 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 911.5 MiB)
25/03/14 11:11:08.762 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53646 (size: 10.6 KiB, free: 912.2 MiB)
25/03/14 11:11:08.762 dag-scheduler-event-loop INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:08.764 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[22] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:11:08.764 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks resource profile 0
25/03/14 11:11:08.766 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:08.766 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:08.767 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:08.767 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:08.767 Executor task launch worker for task 3.0 in stage 2.0 (TID 8) INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
25/03/14 11:11:08.767 Executor task launch worker for task 0.0 in stage 2.0 (TID 5) INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
25/03/14 11:11:08.767 Executor task launch worker for task 2.0 in stage 2.0 (TID 7) INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
25/03/14 11:11:08.767 Executor task launch worker for task 1.0 in stage 2.0 (TID 6) INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
25/03/14 11:11:08.816 Executor task launch worker for task 1.0 in stage 2.0 (TID 6) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:11:08.816 Executor task launch worker for task 3.0 in stage 2.0 (TID 8) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:11:08.816 Executor task launch worker for task 0.0 in stage 2.0 (TID 5) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:11:08.816 Executor task launch worker for task 2.0 in stage 2.0 (TID 7) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:11:08.835 Executor task launch worker for task 2.0 in stage 2.0 (TID 7) INFO CodeGenerator: Code generated in 13.0835 ms
25/03/14 11:11:09.105 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53646 in memory (size: 11.9 KiB, free: 912.2 MiB)
25/03/14 11:11:09.118 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 912.3 MiB)
25/03/14 11:11:09.440 Executor task launch worker for task 3.0 in stage 2.0 (TID 8) INFO MemoryStore: Block rdd_17_3 stored as values in memory (estimated size 2.8 MiB, free 909.1 MiB)
25/03/14 11:11:09.441 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_17_3 in memory on 127.0.0.1:53646 (size: 2.8 MiB, free: 909.4 MiB)
25/03/14 11:11:09.455 Executor task launch worker for task 3.0 in stage 2.0 (TID 8) INFO CodeGenerator: Code generated in 4.6307 ms
25/03/14 11:11:09.773 Executor task launch worker for task 2.0 in stage 2.0 (TID 7) INFO MemoryStore: Block rdd_17_2 stored as values in memory (estimated size 3.1 MiB, free 906.0 MiB)
25/03/14 11:11:09.775 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_17_2 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 906.4 MiB)
25/03/14 11:11:09.781 Executor task launch worker for task 1.0 in stage 2.0 (TID 6) INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 3.1 MiB, free 902.9 MiB)
25/03/14 11:11:09.784 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_17_1 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 903.3 MiB)
25/03/14 11:11:09.803 Executor task launch worker for task 0.0 in stage 2.0 (TID 5) INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 3.1 MiB, free 899.8 MiB)
25/03/14 11:11:09.804 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_17_0 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 900.2 MiB)
25/03/14 11:11:09.807 Executor task launch worker for task 2.0 in stage 2.0 (TID 7) INFO CodeGenerator: Code generated in 28.3491 ms
25/03/14 11:11:09.883 Executor task launch worker for task 0.0 in stage 2.0 (TID 5) INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2162 bytes result sent to driver
25/03/14 11:11:09.885 Executor task launch worker for task 3.0 in stage 2.0 (TID 8) INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 2119 bytes result sent to driver
25/03/14 11:11:09.886 Executor task launch worker for task 2.0 in stage 2.0 (TID 7) INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 2162 bytes result sent to driver
25/03/14 11:11:09.888 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 1122 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:11:09.888 Executor task launch worker for task 1.0 in stage 2.0 (TID 6) INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 2162 bytes result sent to driver
25/03/14 11:11:09.892 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 1125 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:11:09.892 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 1126 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:11:09.892 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 1126 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:11:09.892 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
25/03/14 11:11:09.893 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 1,159 s
25/03/14 11:11:09.894 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 11:11:09.894 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 11:11:09.895 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 11:11:09.895 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 11:11:09.932 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.5238 ms
25/03/14 11:11:09.954 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
25/03/14 11:11:09.955 dag-scheduler-event-loop INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/14 11:11:09.955 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
25/03/14 11:11:09.955 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
25/03/14 11:11:09.955 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:09.956 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[25] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:11:09.963 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.1 KiB, free 899.8 MiB)
25/03/14 11:11:09.966 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 899.8 MiB)
25/03/14 11:11:09.967 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53646 (size: 5.5 KiB, free: 900.2 MiB)
25/03/14 11:11:09.968 dag-scheduler-event-loop INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:09.968 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[25] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:11:09.968 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
25/03/14 11:11:09.972 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 9) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 11:11:09.973 Executor task launch worker for task 0.0 in stage 4.0 (TID 9) INFO Executor: Running task 0.0 in stage 4.0 (TID 9)
25/03/14 11:11:10.002 Executor task launch worker for task 0.0 in stage 4.0 (TID 9) INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 11:11:10.004 Executor task launch worker for task 0.0 in stage 4.0 (TID 9) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
25/03/14 11:11:10.026 Executor task launch worker for task 0.0 in stage 4.0 (TID 9) INFO Executor: Finished task 0.0 in stage 4.0 (TID 9). 2613 bytes result sent to driver
25/03/14 11:11:10.027 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 9) in 56 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:11:10.028 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
25/03/14 11:11:10.028 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0,067 s
25/03/14 11:11:10.029 dag-scheduler-event-loop INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:11:10.029 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
25/03/14 11:11:10.030 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 0,076562 s
25/03/14 11:11:10.151 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 30 (collect at utils.scala:26) as input to shuffle 1
25/03/14 11:11:10.151 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 5 (collect at utils.scala:26) with 4 output partitions
25/03/14 11:11:10.151 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 5 (collect at utils.scala:26)
25/03/14 11:11:10.151 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:11:10.153 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:10.154 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[30] at collect at utils.scala:26), which has no missing parents
25/03/14 11:11:10.161 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 24.4 KiB, free 899.8 MiB)
25/03/14 11:11:10.165 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 899.8 MiB)
25/03/14 11:11:10.167 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53646 (size: 10.6 KiB, free: 900.2 MiB)
25/03/14 11:11:10.171 dag-scheduler-event-loop INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:10.173 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[30] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:11:10.174 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks resource profile 0
25/03/14 11:11:10.179 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:10.180 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 11) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:10.181 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 12) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:10.181 dispatcher-event-loop-6 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 13) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:11:10.182 Executor task launch worker for task 3.0 in stage 5.0 (TID 13) INFO Executor: Running task 3.0 in stage 5.0 (TID 13)
25/03/14 11:11:10.182 Executor task launch worker for task 1.0 in stage 5.0 (TID 11) INFO Executor: Running task 1.0 in stage 5.0 (TID 11)
25/03/14 11:11:10.182 Executor task launch worker for task 0.0 in stage 5.0 (TID 10) INFO Executor: Running task 0.0 in stage 5.0 (TID 10)
25/03/14 11:11:10.182 Executor task launch worker for task 2.0 in stage 5.0 (TID 12) INFO Executor: Running task 2.0 in stage 5.0 (TID 12)
25/03/14 11:11:10.187 Executor task launch worker for task 1.0 in stage 5.0 (TID 11) INFO BlockManager: Found block rdd_17_1 locally
25/03/14 11:11:10.187 Executor task launch worker for task 0.0 in stage 5.0 (TID 10) INFO BlockManager: Found block rdd_17_0 locally
25/03/14 11:11:10.188 Executor task launch worker for task 3.0 in stage 5.0 (TID 13) INFO BlockManager: Found block rdd_17_3 locally
25/03/14 11:11:10.195 Executor task launch worker for task 2.0 in stage 5.0 (TID 12) INFO BlockManager: Found block rdd_17_2 locally
25/03/14 11:11:10.202 Executor task launch worker for task 3.0 in stage 5.0 (TID 13) INFO Executor: Finished task 3.0 in stage 5.0 (TID 13). 2076 bytes result sent to driver
25/03/14 11:11:10.202 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 13) in 21 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:11:10.204 Executor task launch worker for task 2.0 in stage 5.0 (TID 12) INFO Executor: Finished task 2.0 in stage 5.0 (TID 12). 2033 bytes result sent to driver
25/03/14 11:11:10.204 task-result-getter-3 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 12) in 23 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:11:10.205 Executor task launch worker for task 1.0 in stage 5.0 (TID 11) INFO Executor: Finished task 1.0 in stage 5.0 (TID 11). 2033 bytes result sent to driver
25/03/14 11:11:10.206 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 11) in 27 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:11:10.208 Executor task launch worker for task 0.0 in stage 5.0 (TID 10) INFO Executor: Finished task 0.0 in stage 5.0 (TID 10). 2033 bytes result sent to driver
25/03/14 11:11:10.209 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 32 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:11:10.209 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
25/03/14 11:11:10.209 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:26) finished in 0,054 s
25/03/14 11:11:10.210 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 11:11:10.210 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 11:11:10.210 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 11:11:10.210 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 11:11:10.229 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:11:10.231 dag-scheduler-event-loop INFO DAGScheduler: Got job 6 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:11:10.231 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:26)
25/03/14 11:11:10.231 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
25/03/14 11:11:10.231 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:10.232 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[33] at collect at utils.scala:26), which has no missing parents
25/03/14 11:11:10.233 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 11.1 KiB, free 899.7 MiB)
25/03/14 11:11:10.236 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 899.7 MiB)
25/03/14 11:11:10.236 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53646 (size: 5.5 KiB, free: 900.2 MiB)
25/03/14 11:11:10.236 dag-scheduler-event-loop INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:10.237 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:11:10.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
25/03/14 11:11:10.239 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 11:11:10.239 Executor task launch worker for task 0.0 in stage 7.0 (TID 14) INFO Executor: Running task 0.0 in stage 7.0 (TID 14)
25/03/14 11:11:10.244 Executor task launch worker for task 0.0 in stage 7.0 (TID 14) INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 11:11:10.245 Executor task launch worker for task 0.0 in stage 7.0 (TID 14) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 11:11:10.246 Executor task launch worker for task 0.0 in stage 7.0 (TID 14) INFO Executor: Finished task 0.0 in stage 7.0 (TID 14). 2570 bytes result sent to driver
25/03/14 11:11:10.247 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 10 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:11:10.247 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
25/03/14 11:11:10.248 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 7 (collect at utils.scala:26) finished in 0,015 s
25/03/14 11:11:10.248 dag-scheduler-event-loop INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:11:10.248 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
25/03/14 11:11:10.248 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 6 finished: collect at utils.scala:26, took 0,018514 s
25/03/14 11:11:10.257 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 6.3401 ms
25/03/14 11:11:10.671 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 21.5038 ms
25/03/14 11:11:10.726 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:11:10.729 dag-scheduler-event-loop INFO DAGScheduler: Got job 7 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:11:10.729 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:26)
25/03/14 11:11:10.729 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:11:10.730 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:11:10.731 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[36] at collect at utils.scala:26), which has no missing parents
25/03/14 11:11:10.733 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.3 KiB, free 899.7 MiB)
25/03/14 11:11:10.738 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 899.7 MiB)
25/03/14 11:11:10.739 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53646 (size: 3.7 KiB, free: 900.2 MiB)
25/03/14 11:11:10.739 dag-scheduler-event-loop INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
25/03/14 11:11:10.740 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[36] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:11:10.740 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
25/03/14 11:11:10.749 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 15) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 11:11:10.750 Executor task launch worker for task 0.0 in stage 8.0 (TID 15) INFO Executor: Running task 0.0 in stage 8.0 (TID 15)
25/03/14 11:11:10.765 Executor task launch worker for task 0.0 in stage 8.0 (TID 15) INFO Executor: Finished task 0.0 in stage 8.0 (TID 15). 1319 bytes result sent to driver
25/03/14 11:11:10.767 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 15) in 24 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:11:10.768 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
25/03/14 11:11:10.768 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 8 (collect at utils.scala:26) finished in 0,037 s
25/03/14 11:11:10.768 dag-scheduler-event-loop INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:11:10.768 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
25/03/14 11:11:10.768 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 7 finished: collect at utils.scala:26, took 0,041994 s
25/03/14 11:11:10.780 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.1287 ms
25/03/14 11:11:11.029 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:11.029 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:11.031 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:11.031 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:11.034 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:11:11.034 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:11:11.101 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 42.1437 ms
25/03/14 11:11:11.140 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 9.614 ms
25/03/14 11:11:11.156 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.9237 ms
25/03/14 11:11:11.188 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:11.188 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:11.190 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:11:11.190 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:11:11.191 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:11:11.191 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:13:25.130 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:13:25.131 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:13:25.133 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:13:25.133 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:13:25.137 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:13:25.137 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:13:25.213 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:13:25.213 dag-scheduler-event-loop INFO DAGScheduler: Got job 8 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:13:25.213 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:26)
25/03/14 11:13:25.213 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:13:25.213 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:25.214 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at collect at utils.scala:26), which has no missing parents
25/03/14 11:13:25.217 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.1 KiB, free 899.7 MiB)
25/03/14 11:13:25.224 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 899.7 MiB)
25/03/14 11:13:25.225 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53646 (size: 3.7 KiB, free: 900.2 MiB)
25/03/14 11:13:25.226 dag-scheduler-event-loop INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:25.226 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:13:25.226 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
25/03/14 11:13:25.230 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 16) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4657 bytes) taskResourceAssignments Map()
25/03/14 11:13:25.231 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO Executor: Running task 0.0 in stage 9.0 (TID 16)
25/03/14 11:13:25.235 Executor task launch worker for task 0.0 in stage 9.0 (TID 16) INFO Executor: Finished task 0.0 in stage 9.0 (TID 16). 1342 bytes result sent to driver
25/03/14 11:13:25.237 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 16) in 9 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:13:25.237 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
25/03/14 11:13:25.237 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 9 (collect at utils.scala:26) finished in 0,023 s
25/03/14 11:13:25.237 dag-scheduler-event-loop INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:13:25.237 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
25/03/14 11:13:25.237 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 8 finished: collect at utils.scala:26, took 0,024477 s
25/03/14 11:13:25.248 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 8.7377 ms
25/03/14 11:13:25.298 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 17 from persistence list
25/03/14 11:13:25.304 block-manager-storage-async-thread-pool-12 INFO BlockManager: Removing RDD 17
25/03/14 11:13:25.321 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/03/14 11:13:25.418 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.
25/03/14 11:13:25.428 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/03/14 11:13:25.528 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:13:25.528 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#533, None)) > 0)
25/03/14 11:13:25.528 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:13:25.537 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 358.6 KiB, free 911.4 MiB)
25/03/14 11:13:25.566 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 911.4 MiB)
25/03/14 11:13:25.567 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 912.2 MiB)
25/03/14 11:13:25.567 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 11 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:13:25.568 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:13:25.587 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:13:25.588 dag-scheduler-event-loop INFO DAGScheduler: Got job 9 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/14 11:13:25.588 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:13:25.588 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:13:25.588 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:25.589 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[43] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:13:25.592 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 11.8 KiB, free 911.4 MiB)
25/03/14 11:13:25.605 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 911.4 MiB)
25/03/14 11:13:25.606 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53646 (size: 5.9 KiB, free: 912.2 MiB)
25/03/14 11:13:25.606 dag-scheduler-event-loop INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:25.607 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[43] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:13:25.607 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
25/03/14 11:13:25.608 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 17) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:13:25.609 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO Executor: Running task 0.0 in stage 10.0 (TID 17)
25/03/14 11:13:25.615 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:13:25.625 Executor task launch worker for task 0.0 in stage 10.0 (TID 17) INFO Executor: Finished task 0.0 in stage 10.0 (TID 17). 1501 bytes result sent to driver
25/03/14 11:13:25.626 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 17) in 18 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:13:25.626 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
25/03/14 11:13:25.627 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 10 (csv at NativeMethodAccessorImpl.java:0) finished in 0,036 s
25/03/14 11:13:25.627 dag-scheduler-event-loop INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:13:25.627 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
25/03/14 11:13:25.627 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 9 finished: csv at NativeMethodAccessorImpl.java:0, took 0,039430 s
25/03/14 11:13:25.644 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:13:25.644 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:13:25.645 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:13:25.649 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 358.6 KiB, free 911.0 MiB)
25/03/14 11:13:25.686 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 911.0 MiB)
25/03/14 11:13:25.687 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 912.2 MiB)
25/03/14 11:13:25.688 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 13 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:13:25.689 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:13:25.718 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:13:25.719 dag-scheduler-event-loop INFO DAGScheduler: Got job 10 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/03/14 11:13:25.719 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:13:25.719 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:13:25.719 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:25.720 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:13:25.725 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 25.2 KiB, free 911.0 MiB)
25/03/14 11:13:25.741 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.9 KiB, free 911.0 MiB)
25/03/14 11:13:25.742 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53646 (size: 11.9 KiB, free: 912.1 MiB)
25/03/14 11:13:25.742 dag-scheduler-event-loop INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:25.743 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:13:25.743 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks resource profile 0
25/03/14 11:13:25.744 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 18) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:13:25.745 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 19) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:13:25.745 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 20) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:13:25.745 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 21) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:13:25.745 Executor task launch worker for task 0.0 in stage 11.0 (TID 18) INFO Executor: Running task 0.0 in stage 11.0 (TID 18)
25/03/14 11:13:25.747 Executor task launch worker for task 1.0 in stage 11.0 (TID 19) INFO Executor: Running task 1.0 in stage 11.0 (TID 19)
25/03/14 11:13:25.748 Executor task launch worker for task 3.0 in stage 11.0 (TID 21) INFO Executor: Running task 3.0 in stage 11.0 (TID 21)
25/03/14 11:13:25.748 Executor task launch worker for task 2.0 in stage 11.0 (TID 20) INFO Executor: Running task 2.0 in stage 11.0 (TID 20)
25/03/14 11:13:25.761 Executor task launch worker for task 3.0 in stage 11.0 (TID 21) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:13:25.761 Executor task launch worker for task 2.0 in stage 11.0 (TID 20) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:13:25.762 Executor task launch worker for task 1.0 in stage 11.0 (TID 19) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:13:25.765 Executor task launch worker for task 0.0 in stage 11.0 (TID 18) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:13:26.300 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53646 in memory (size: 3.7 KiB, free: 912.1 MiB)
25/03/14 11:13:26.304 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53646 in memory (size: 10.6 KiB, free: 912.2 MiB)
25/03/14 11:13:26.310 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53646 in memory (size: 5.9 KiB, free: 912.2 MiB)
25/03/14 11:13:26.313 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53646 in memory (size: 3.7 KiB, free: 912.2 MiB)
25/03/14 11:13:26.329 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53646 in memory (size: 5.5 KiB, free: 912.2 MiB)
25/03/14 11:13:26.346 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 912.2 MiB)
25/03/14 11:13:26.378 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53646 in memory (size: 5.5 KiB, free: 912.2 MiB)
25/03/14 11:13:26.402 Executor task launch worker for task 3.0 in stage 11.0 (TID 21) INFO Executor: Finished task 3.0 in stage 11.0 (TID 21). 1634 bytes result sent to driver
25/03/14 11:13:26.404 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 21) in 659 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:13:26.420 Executor task launch worker for task 1.0 in stage 11.0 (TID 19) INFO Executor: Finished task 1.0 in stage 11.0 (TID 19). 1634 bytes result sent to driver
25/03/14 11:13:26.422 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 19) in 678 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:13:26.424 Executor task launch worker for task 0.0 in stage 11.0 (TID 18) INFO Executor: Finished task 0.0 in stage 11.0 (TID 18). 1634 bytes result sent to driver
25/03/14 11:13:26.425 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 18) in 681 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:13:26.425 Executor task launch worker for task 2.0 in stage 11.0 (TID 20) INFO Executor: Finished task 2.0 in stage 11.0 (TID 20). 1634 bytes result sent to driver
25/03/14 11:13:26.427 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 20) in 682 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:13:26.427 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
25/03/14 11:13:26.427 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0) finished in 0,706 s
25/03/14 11:13:26.428 dag-scheduler-event-loop INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:13:26.428 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
25/03/14 11:13:26.428 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 10 finished: csv at NativeMethodAccessorImpl.java:0, took 0,709471 s
25/03/14 11:13:26.454 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:13:26.454 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:13:26.456 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:13:26.456 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:13:26.458 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:13:26.458 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:13:26.528 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:13:26.528 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:13:26.528 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<Order ID: int, Product: string, Quantity Ordered: int, Price Each: double, Order Date: string ... 1 more field>
25/03/14 11:13:26.556 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 358.5 KiB, free 911.1 MiB)
25/03/14 11:13:26.568 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 911.1 MiB)
25/03/14 11:13:26.568 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53646 (size: 34.8 KiB, free: 912.2 MiB)
25/03/14 11:13:26.569 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 15 from sql at NativeMethodAccessorImpl.java:0
25/03/14 11:13:26.570 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:13:26.581 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 59 (sql at NativeMethodAccessorImpl.java:0) as input to shuffle 2
25/03/14 11:13:26.581 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 11 (sql at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/03/14 11:13:26.581 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 12 (sql at NativeMethodAccessorImpl.java:0)
25/03/14 11:13:26.581 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:13:26.583 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:26.583 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[59] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:13:26.588 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 24.4 KiB, free 911.1 MiB)
25/03/14 11:13:26.598 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 911.0 MiB)
25/03/14 11:13:26.600 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53646 (size: 10.6 KiB, free: 912.2 MiB)
25/03/14 11:13:26.600 dag-scheduler-event-loop INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:26.601 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[59] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:13:26.601 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks resource profile 0
25/03/14 11:13:26.602 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 22) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.602 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 23) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.603 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 24) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.603 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 25) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.603 Executor task launch worker for task 1.0 in stage 12.0 (TID 23) INFO Executor: Running task 1.0 in stage 12.0 (TID 23)
25/03/14 11:13:26.603 Executor task launch worker for task 0.0 in stage 12.0 (TID 22) INFO Executor: Running task 0.0 in stage 12.0 (TID 22)
25/03/14 11:13:26.603 Executor task launch worker for task 2.0 in stage 12.0 (TID 24) INFO Executor: Running task 2.0 in stage 12.0 (TID 24)
25/03/14 11:13:26.603 Executor task launch worker for task 3.0 in stage 12.0 (TID 25) INFO Executor: Running task 3.0 in stage 12.0 (TID 25)
25/03/14 11:13:26.611 Executor task launch worker for task 1.0 in stage 12.0 (TID 23) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:13:26.612 Executor task launch worker for task 3.0 in stage 12.0 (TID 25) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:13:26.612 Executor task launch worker for task 0.0 in stage 12.0 (TID 22) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:13:26.613 Executor task launch worker for task 2.0 in stage 12.0 (TID 24) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:13:26.777 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53646 in memory (size: 11.9 KiB, free: 912.2 MiB)
25/03/14 11:13:26.783 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 912.2 MiB)
25/03/14 11:13:26.874 Executor task launch worker for task 3.0 in stage 12.0 (TID 25) INFO MemoryStore: Block rdd_54_3 stored as values in memory (estimated size 2.8 MiB, free 908.7 MiB)
25/03/14 11:13:26.875 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_54_3 in memory on 127.0.0.1:53646 (size: 2.8 MiB, free: 909.4 MiB)
25/03/14 11:13:26.881 Executor task launch worker for task 3.0 in stage 12.0 (TID 25) INFO Executor: Finished task 3.0 in stage 12.0 (TID 25). 2119 bytes result sent to driver
25/03/14 11:13:26.882 Executor task launch worker for task 0.0 in stage 12.0 (TID 22) INFO MemoryStore: Block rdd_54_0 stored as values in memory (estimated size 3.1 MiB, free 905.6 MiB)
25/03/14 11:13:26.882 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 25) in 279 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:13:26.882 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_54_0 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 906.3 MiB)
25/03/14 11:13:26.887 Executor task launch worker for task 0.0 in stage 12.0 (TID 22) INFO Executor: Finished task 0.0 in stage 12.0 (TID 22). 2119 bytes result sent to driver
25/03/14 11:13:26.888 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 22) in 287 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:13:26.897 Executor task launch worker for task 2.0 in stage 12.0 (TID 24) INFO MemoryStore: Block rdd_54_2 stored as values in memory (estimated size 3.1 MiB, free 902.5 MiB)
25/03/14 11:13:26.898 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_54_2 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 903.2 MiB)
25/03/14 11:13:26.899 Executor task launch worker for task 1.0 in stage 12.0 (TID 23) INFO MemoryStore: Block rdd_54_1 stored as values in memory (estimated size 3.1 MiB, free 899.4 MiB)
25/03/14 11:13:26.899 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_54_1 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 900.1 MiB)
25/03/14 11:13:26.903 Executor task launch worker for task 2.0 in stage 12.0 (TID 24) INFO Executor: Finished task 2.0 in stage 12.0 (TID 24). 2119 bytes result sent to driver
25/03/14 11:13:26.903 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 24) in 301 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:13:26.905 Executor task launch worker for task 1.0 in stage 12.0 (TID 23) INFO Executor: Finished task 1.0 in stage 12.0 (TID 23). 2119 bytes result sent to driver
25/03/14 11:13:26.905 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 23) in 303 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:13:26.905 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
25/03/14 11:13:26.906 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0,322 s
25/03/14 11:13:26.906 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 11:13:26.906 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 11:13:26.906 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 11:13:26.906 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 11:13:26.919 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
25/03/14 11:13:26.920 dag-scheduler-event-loop INFO DAGScheduler: Got job 12 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/14 11:13:26.920 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 14 (sql at NativeMethodAccessorImpl.java:0)
25/03/14 11:13:26.920 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
25/03/14 11:13:26.920 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:26.921 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:13:26.922 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 11.1 KiB, free 899.4 MiB)
25/03/14 11:13:26.924 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 899.4 MiB)
25/03/14 11:13:26.924 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53646 (size: 5.5 KiB, free: 900.1 MiB)
25/03/14 11:13:26.924 dag-scheduler-event-loop INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:26.925 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:13:26.925 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
25/03/14 11:13:26.925 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 26) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.926 Executor task launch worker for task 0.0 in stage 14.0 (TID 26) INFO Executor: Running task 0.0 in stage 14.0 (TID 26)
25/03/14 11:13:26.927 Executor task launch worker for task 0.0 in stage 14.0 (TID 26) INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 11:13:26.928 Executor task launch worker for task 0.0 in stage 14.0 (TID 26) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 11:13:26.929 Executor task launch worker for task 0.0 in stage 14.0 (TID 26) INFO Executor: Finished task 0.0 in stage 14.0 (TID 26). 2570 bytes result sent to driver
25/03/14 11:13:26.930 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 26) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:13:26.930 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
25/03/14 11:13:26.930 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 14 (sql at NativeMethodAccessorImpl.java:0) finished in 0,008 s
25/03/14 11:13:26.930 dag-scheduler-event-loop INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:13:26.930 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
25/03/14 11:13:26.930 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 12 finished: sql at NativeMethodAccessorImpl.java:0, took 0,011607 s
25/03/14 11:13:26.979 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 67 (collect at utils.scala:26) as input to shuffle 3
25/03/14 11:13:26.979 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 13 (collect at utils.scala:26) with 4 output partitions
25/03/14 11:13:26.979 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 15 (collect at utils.scala:26)
25/03/14 11:13:26.979 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:13:26.979 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:26.981 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[67] at collect at utils.scala:26), which has no missing parents
25/03/14 11:13:26.984 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 24.4 KiB, free 899.3 MiB)
25/03/14 11:13:26.985 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 899.3 MiB)
25/03/14 11:13:26.985 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53646 (size: 10.6 KiB, free: 900.1 MiB)
25/03/14 11:13:26.985 dag-scheduler-event-loop INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:26.985 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[67] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:13:26.985 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks resource profile 0
25/03/14 11:13:26.987 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 27) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.987 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 28) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.987 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 29) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.988 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 30) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:13:26.988 Executor task launch worker for task 0.0 in stage 15.0 (TID 27) INFO Executor: Running task 0.0 in stage 15.0 (TID 27)
25/03/14 11:13:26.988 Executor task launch worker for task 1.0 in stage 15.0 (TID 28) INFO Executor: Running task 1.0 in stage 15.0 (TID 28)
25/03/14 11:13:26.988 Executor task launch worker for task 2.0 in stage 15.0 (TID 29) INFO Executor: Running task 2.0 in stage 15.0 (TID 29)
25/03/14 11:13:26.988 Executor task launch worker for task 3.0 in stage 15.0 (TID 30) INFO Executor: Running task 3.0 in stage 15.0 (TID 30)
25/03/14 11:13:26.993 Executor task launch worker for task 1.0 in stage 15.0 (TID 28) INFO BlockManager: Found block rdd_54_1 locally
25/03/14 11:13:26.993 Executor task launch worker for task 2.0 in stage 15.0 (TID 29) INFO BlockManager: Found block rdd_54_2 locally
25/03/14 11:13:26.993 Executor task launch worker for task 0.0 in stage 15.0 (TID 27) INFO BlockManager: Found block rdd_54_0 locally
25/03/14 11:13:26.994 Executor task launch worker for task 3.0 in stage 15.0 (TID 30) INFO BlockManager: Found block rdd_54_3 locally
25/03/14 11:13:26.999 Executor task launch worker for task 0.0 in stage 15.0 (TID 27) INFO Executor: Finished task 0.0 in stage 15.0 (TID 27). 2033 bytes result sent to driver
25/03/14 11:13:27.000 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 27) in 13 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:13:27.002 Executor task launch worker for task 3.0 in stage 15.0 (TID 30) INFO Executor: Finished task 3.0 in stage 15.0 (TID 30). 2033 bytes result sent to driver
25/03/14 11:13:27.002 task-result-getter-0 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 30) in 15 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:13:27.004 Executor task launch worker for task 1.0 in stage 15.0 (TID 28) INFO Executor: Finished task 1.0 in stage 15.0 (TID 28). 2076 bytes result sent to driver
25/03/14 11:13:27.004 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 28) in 17 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:13:27.007 Executor task launch worker for task 2.0 in stage 15.0 (TID 29) INFO Executor: Finished task 2.0 in stage 15.0 (TID 29). 2033 bytes result sent to driver
25/03/14 11:13:27.009 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 29) in 22 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:13:27.009 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
25/03/14 11:13:27.009 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:26) finished in 0,028 s
25/03/14 11:13:27.009 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 11:13:27.009 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 11:13:27.009 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 11:13:27.009 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 11:13:27.029 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:13:27.030 dag-scheduler-event-loop INFO DAGScheduler: Got job 14 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:13:27.030 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:26)
25/03/14 11:13:27.030 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
25/03/14 11:13:27.030 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:27.031 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[70] at collect at utils.scala:26), which has no missing parents
25/03/14 11:13:27.032 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 11.1 KiB, free 899.3 MiB)
25/03/14 11:13:27.034 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 899.3 MiB)
25/03/14 11:13:27.034 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53646 (size: 5.5 KiB, free: 900.1 MiB)
25/03/14 11:13:27.034 dag-scheduler-event-loop INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:27.035 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[70] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:13:27.035 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
25/03/14 11:13:27.035 dispatcher-event-loop-4 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 31) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 11:13:27.037 Executor task launch worker for task 0.0 in stage 17.0 (TID 31) INFO Executor: Running task 0.0 in stage 17.0 (TID 31)
25/03/14 11:13:27.039 Executor task launch worker for task 0.0 in stage 17.0 (TID 31) INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 11:13:27.039 Executor task launch worker for task 0.0 in stage 17.0 (TID 31) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 11:13:27.042 Executor task launch worker for task 0.0 in stage 17.0 (TID 31) INFO Executor: Finished task 0.0 in stage 17.0 (TID 31). 2613 bytes result sent to driver
25/03/14 11:13:27.042 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 31) in 7 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:13:27.042 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
25/03/14 11:13:27.043 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 17 (collect at utils.scala:26) finished in 0,012 s
25/03/14 11:13:27.043 dag-scheduler-event-loop INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:13:27.043 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
25/03/14 11:13:27.043 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 14 finished: collect at utils.scala:26, took 0,014881 s
25/03/14 11:13:27.148 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:13:27.149 dag-scheduler-event-loop INFO DAGScheduler: Got job 15 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:13:27.149 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:26)
25/03/14 11:13:27.149 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:13:27.149 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:13:27.150 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[72] at collect at utils.scala:26), which has no missing parents
25/03/14 11:13:27.151 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.3 KiB, free 899.3 MiB)
25/03/14 11:13:27.152 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 899.3 MiB)
25/03/14 11:13:27.153 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53646 (size: 3.7 KiB, free: 900.1 MiB)
25/03/14 11:13:27.153 dag-scheduler-event-loop INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513
25/03/14 11:13:27.154 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[72] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:13:27.154 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
25/03/14 11:13:27.155 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 32) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 11:13:27.155 Executor task launch worker for task 0.0 in stage 18.0 (TID 32) INFO Executor: Running task 0.0 in stage 18.0 (TID 32)
25/03/14 11:13:27.159 Executor task launch worker for task 0.0 in stage 18.0 (TID 32) INFO Executor: Finished task 0.0 in stage 18.0 (TID 32). 1276 bytes result sent to driver
25/03/14 11:13:27.160 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 32) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:13:27.160 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
25/03/14 11:13:27.160 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 18 (collect at utils.scala:26) finished in 0,010 s
25/03/14 11:13:27.160 dag-scheduler-event-loop INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:13:27.160 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
25/03/14 11:13:27.161 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 15 finished: collect at utils.scala:26, took 0,011900 s
25/03/14 11:13:27.271 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:13:27.271 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:13:27.274 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:13:27.275 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:13:27.276 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:13:27.276 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:14:52.085 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:14:52.085 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:14:52.087 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:14:52.088 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:14:52.089 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:14:52.089 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:14:52.139 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:14:52.140 dag-scheduler-event-loop INFO DAGScheduler: Got job 16 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:14:52.140 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:26)
25/03/14 11:14:52.140 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:52.140 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:52.140 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[75] at collect at utils.scala:26), which has no missing parents
25/03/14 11:14:52.142 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.1 KiB, free 899.3 MiB)
25/03/14 11:14:52.143 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 899.3 MiB)
25/03/14 11:14:52.143 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53646 (size: 3.7 KiB, free: 900.1 MiB)
25/03/14 11:14:52.145 dag-scheduler-event-loop INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:52.145 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[75] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:14:52.145 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
25/03/14 11:14:52.145 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 33) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4657 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.147 Executor task launch worker for task 0.0 in stage 19.0 (TID 33) INFO Executor: Running task 0.0 in stage 19.0 (TID 33)
25/03/14 11:14:52.148 Executor task launch worker for task 0.0 in stage 19.0 (TID 33) INFO Executor: Finished task 0.0 in stage 19.0 (TID 33). 1299 bytes result sent to driver
25/03/14 11:14:52.148 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 33) in 3 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:14:52.148 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
25/03/14 11:14:52.149 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 19 (collect at utils.scala:26) finished in 0,007 s
25/03/14 11:14:52.149 dag-scheduler-event-loop INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:52.149 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
25/03/14 11:14:52.149 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 16 finished: collect at utils.scala:26, took 0,009907 s
25/03/14 11:14:52.177 nioEventLoopGroup-2-2 INFO MapPartitionsRDD: Removing RDD 54 from persistence list
25/03/14 11:14:52.179 block-manager-storage-async-thread-pool-45 INFO BlockManager: Removing RDD 54
25/03/14 11:14:52.180 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/03/14 11:14:52.238 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/03/14 11:14:52.244 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
25/03/14 11:14:52.300 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:14:52.300 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1029, None)) > 0)
25/03/14 11:14:52.300 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:14:52.305 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 358.6 KiB, free 911.0 MiB)
25/03/14 11:14:52.314 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 911.0 MiB)
25/03/14 11:14:52.314 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 912.1 MiB)
25/03/14 11:14:52.315 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 22 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:14:52.316 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:14:52.322 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:14:52.323 dag-scheduler-event-loop INFO DAGScheduler: Got job 17 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/14 11:14:52.323 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 20 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:14:52.323 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:52.323 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:52.324 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[79] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:14:52.327 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 11.8 KiB, free 911.0 MiB)
25/03/14 11:14:52.327 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 911.0 MiB)
25/03/14 11:14:52.328 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53646 (size: 5.9 KiB, free: 912.1 MiB)
25/03/14 11:14:52.328 dag-scheduler-event-loop INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:52.328 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[79] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:14:52.328 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
25/03/14 11:14:52.329 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 34) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.329 Executor task launch worker for task 0.0 in stage 20.0 (TID 34) INFO Executor: Running task 0.0 in stage 20.0 (TID 34)
25/03/14 11:14:52.331 Executor task launch worker for task 0.0 in stage 20.0 (TID 34) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:14:52.334 Executor task launch worker for task 0.0 in stage 20.0 (TID 34) INFO Executor: Finished task 0.0 in stage 20.0 (TID 34). 1501 bytes result sent to driver
25/03/14 11:14:52.334 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 34) in 5 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:14:52.334 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
25/03/14 11:14:52.334 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 20 (csv at NativeMethodAccessorImpl.java:0) finished in 0,010 s
25/03/14 11:14:52.335 dag-scheduler-event-loop INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:52.335 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
25/03/14 11:14:52.335 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 17 finished: csv at NativeMethodAccessorImpl.java:0, took 0,012598 s
25/03/14 11:14:52.342 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:14:52.342 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:14:52.342 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:14:52.345 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 358.6 KiB, free 910.6 MiB)
25/03/14 11:14:52.353 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 910.6 MiB)
25/03/14 11:14:52.353 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 912.1 MiB)
25/03/14 11:14:52.354 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 24 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:14:52.354 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:14:52.367 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:14:52.368 dag-scheduler-event-loop INFO DAGScheduler: Got job 18 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/03/14 11:14:52.368 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 21 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:14:52.368 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:52.368 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:52.368 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[85] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:14:52.370 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 25.2 KiB, free 910.6 MiB)
25/03/14 11:14:52.371 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 11.9 KiB, free 910.6 MiB)
25/03/14 11:14:52.372 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53646 (size: 11.9 KiB, free: 912.1 MiB)
25/03/14 11:14:52.372 dag-scheduler-event-loop INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:52.372 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[85] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:14:52.372 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks resource profile 0
25/03/14 11:14:52.374 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 35) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.375 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 36) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.375 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 37) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.375 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 38) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.376 Executor task launch worker for task 0.0 in stage 21.0 (TID 35) INFO Executor: Running task 0.0 in stage 21.0 (TID 35)
25/03/14 11:14:52.376 Executor task launch worker for task 1.0 in stage 21.0 (TID 36) INFO Executor: Running task 1.0 in stage 21.0 (TID 36)
25/03/14 11:14:52.377 Executor task launch worker for task 2.0 in stage 21.0 (TID 37) INFO Executor: Running task 2.0 in stage 21.0 (TID 37)
25/03/14 11:14:52.377 Executor task launch worker for task 3.0 in stage 21.0 (TID 38) INFO Executor: Running task 3.0 in stage 21.0 (TID 38)
25/03/14 11:14:52.382 Executor task launch worker for task 2.0 in stage 21.0 (TID 37) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:14:52.382 Executor task launch worker for task 1.0 in stage 21.0 (TID 36) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:14:52.382 Executor task launch worker for task 0.0 in stage 21.0 (TID 35) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:14:52.382 Executor task launch worker for task 3.0 in stage 21.0 (TID 38) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:14:52.465 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53646 in memory (size: 10.6 KiB, free: 912.1 MiB)
25/03/14 11:14:52.467 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 912.1 MiB)
25/03/14 11:14:52.471 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53646 in memory (size: 5.9 KiB, free: 912.1 MiB)
25/03/14 11:14:52.478 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53646 in memory (size: 3.7 KiB, free: 912.2 MiB)
25/03/14 11:14:52.480 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53646 in memory (size: 5.5 KiB, free: 912.2 MiB)
25/03/14 11:14:52.482 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53646 in memory (size: 3.7 KiB, free: 912.2 MiB)
25/03/14 11:14:52.486 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53646 in memory (size: 5.5 KiB, free: 912.2 MiB)
25/03/14 11:14:52.526 Executor task launch worker for task 3.0 in stage 21.0 (TID 38) INFO Executor: Finished task 3.0 in stage 21.0 (TID 38). 1634 bytes result sent to driver
25/03/14 11:14:52.527 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 38) in 152 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:14:52.529 Executor task launch worker for task 1.0 in stage 21.0 (TID 36) INFO Executor: Finished task 1.0 in stage 21.0 (TID 36). 1634 bytes result sent to driver
25/03/14 11:14:52.529 Executor task launch worker for task 2.0 in stage 21.0 (TID 37) INFO Executor: Finished task 2.0 in stage 21.0 (TID 37). 1634 bytes result sent to driver
25/03/14 11:14:52.529 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 36) in 154 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:14:52.529 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 37) in 154 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:14:52.532 Executor task launch worker for task 0.0 in stage 21.0 (TID 35) INFO Executor: Finished task 0.0 in stage 21.0 (TID 35). 1634 bytes result sent to driver
25/03/14 11:14:52.532 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 35) in 158 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:14:52.532 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
25/03/14 11:14:52.532 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 21 (csv at NativeMethodAccessorImpl.java:0) finished in 0,163 s
25/03/14 11:14:52.532 dag-scheduler-event-loop INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:52.532 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
25/03/14 11:14:52.532 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 18 finished: csv at NativeMethodAccessorImpl.java:0, took 0,166301 s
25/03/14 11:14:52.567 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:14:52.567 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:14:52.569 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:14:52.569 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:14:52.570 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:14:52.570 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:14:52.626 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:14:52.626 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:14:52.626 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<Order ID: int, Product: string, Quantity Ordered: int, Price Each: double, Order Date: string ... 1 more field>
25/03/14 11:14:52.646 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 358.5 KiB, free 910.7 MiB)
25/03/14 11:14:52.653 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 910.7 MiB)
25/03/14 11:14:52.653 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53646 (size: 34.8 KiB, free: 912.1 MiB)
25/03/14 11:14:52.654 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 26 from sql at <unknown>:0
25/03/14 11:14:52.655 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:14:52.664 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 95 (sql at <unknown>:0) as input to shuffle 4
25/03/14 11:14:52.664 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 19 (sql at <unknown>:0) with 4 output partitions
25/03/14 11:14:52.665 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 22 (sql at <unknown>:0)
25/03/14 11:14:52.665 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:52.665 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:52.666 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[95] at sql at <unknown>:0), which has no missing parents
25/03/14 11:14:52.671 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 24.4 KiB, free 910.6 MiB)
25/03/14 11:14:52.672 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 910.6 MiB)
25/03/14 11:14:52.673 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53646 (size: 10.6 KiB, free: 912.1 MiB)
25/03/14 11:14:52.673 dag-scheduler-event-loop INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:52.674 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[95] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:14:52.674 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks resource profile 0
25/03/14 11:14:52.674 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 39) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.675 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 40) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.675 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 41) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.675 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 42) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.675 Executor task launch worker for task 3.0 in stage 22.0 (TID 42) INFO Executor: Running task 3.0 in stage 22.0 (TID 42)
25/03/14 11:14:52.675 Executor task launch worker for task 2.0 in stage 22.0 (TID 41) INFO Executor: Running task 2.0 in stage 22.0 (TID 41)
25/03/14 11:14:52.675 Executor task launch worker for task 1.0 in stage 22.0 (TID 40) INFO Executor: Running task 1.0 in stage 22.0 (TID 40)
25/03/14 11:14:52.675 Executor task launch worker for task 0.0 in stage 22.0 (TID 39) INFO Executor: Running task 0.0 in stage 22.0 (TID 39)
25/03/14 11:14:52.678 Executor task launch worker for task 2.0 in stage 22.0 (TID 41) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:14:52.678 Executor task launch worker for task 0.0 in stage 22.0 (TID 39) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:14:52.678 Executor task launch worker for task 3.0 in stage 22.0 (TID 42) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:14:52.678 Executor task launch worker for task 1.0 in stage 22.0 (TID 40) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:14:52.911 Executor task launch worker for task 3.0 in stage 22.0 (TID 42) INFO MemoryStore: Block rdd_90_3 stored as values in memory (estimated size 2.8 MiB, free 907.8 MiB)
25/03/14 11:14:52.911 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_90_3 in memory on 127.0.0.1:53646 (size: 2.8 MiB, free: 909.3 MiB)
25/03/14 11:14:52.919 Executor task launch worker for task 3.0 in stage 22.0 (TID 42) INFO Executor: Finished task 3.0 in stage 22.0 (TID 42). 2119 bytes result sent to driver
25/03/14 11:14:52.919 task-result-getter-3 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 42) in 244 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:14:52.923 Executor task launch worker for task 1.0 in stage 22.0 (TID 40) INFO MemoryStore: Block rdd_90_1 stored as values in memory (estimated size 3.1 MiB, free 904.7 MiB)
25/03/14 11:14:52.924 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_90_1 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 906.2 MiB)
25/03/14 11:14:52.930 Executor task launch worker for task 1.0 in stage 22.0 (TID 40) INFO Executor: Finished task 1.0 in stage 22.0 (TID 40). 2076 bytes result sent to driver
25/03/14 11:14:52.930 task-result-getter-0 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 40) in 256 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:14:52.932 Executor task launch worker for task 2.0 in stage 22.0 (TID 41) INFO MemoryStore: Block rdd_90_2 stored as values in memory (estimated size 3.1 MiB, free 901.6 MiB)
25/03/14 11:14:52.932 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_90_2 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 903.1 MiB)
25/03/14 11:14:52.940 Executor task launch worker for task 2.0 in stage 22.0 (TID 41) INFO Executor: Finished task 2.0 in stage 22.0 (TID 41). 2119 bytes result sent to driver
25/03/14 11:14:52.941 task-result-getter-1 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 41) in 266 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:14:52.941 Executor task launch worker for task 0.0 in stage 22.0 (TID 39) INFO MemoryStore: Block rdd_90_0 stored as values in memory (estimated size 3.1 MiB, free 898.5 MiB)
25/03/14 11:14:52.941 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added rdd_90_0 in memory on 127.0.0.1:53646 (size: 3.1 MiB, free: 900.0 MiB)
25/03/14 11:14:52.946 Executor task launch worker for task 0.0 in stage 22.0 (TID 39) INFO Executor: Finished task 0.0 in stage 22.0 (TID 39). 2119 bytes result sent to driver
25/03/14 11:14:52.947 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 39) in 273 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:14:52.947 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
25/03/14 11:14:52.947 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 22 (sql at <unknown>:0) finished in 0,281 s
25/03/14 11:14:52.947 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 11:14:52.947 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 11:14:52.947 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 11:14:52.947 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 11:14:52.960 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: sql at <unknown>:0
25/03/14 11:14:52.960 dag-scheduler-event-loop INFO DAGScheduler: Got job 20 (sql at <unknown>:0) with 1 output partitions
25/03/14 11:14:52.960 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 24 (sql at <unknown>:0)
25/03/14 11:14:52.960 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
25/03/14 11:14:52.962 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:52.962 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[98] at sql at <unknown>:0), which has no missing parents
25/03/14 11:14:52.963 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 11.1 KiB, free 898.5 MiB)
25/03/14 11:14:52.964 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 898.5 MiB)
25/03/14 11:14:52.964 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53646 (size: 5.5 KiB, free: 900.0 MiB)
25/03/14 11:14:52.964 dag-scheduler-event-loop INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:52.965 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[98] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:14:52.965 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
25/03/14 11:14:52.966 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 43) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 11:14:52.966 Executor task launch worker for task 0.0 in stage 24.0 (TID 43) INFO Executor: Running task 0.0 in stage 24.0 (TID 43)
25/03/14 11:14:52.969 Executor task launch worker for task 0.0 in stage 24.0 (TID 43) INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 11:14:52.969 Executor task launch worker for task 0.0 in stage 24.0 (TID 43) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 11:14:52.971 Executor task launch worker for task 0.0 in stage 24.0 (TID 43) INFO Executor: Finished task 0.0 in stage 24.0 (TID 43). 2570 bytes result sent to driver
25/03/14 11:14:52.972 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 43) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:14:52.972 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
25/03/14 11:14:52.972 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 24 (sql at <unknown>:0) finished in 0,010 s
25/03/14 11:14:52.973 dag-scheduler-event-loop INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:52.973 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
25/03/14 11:14:52.973 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 20 finished: sql at <unknown>:0, took 0,012806 s
25/03/14 11:14:53.027 dag-scheduler-event-loop INFO DAGScheduler: Registering RDD 103 (collect at utils.scala:26) as input to shuffle 5
25/03/14 11:14:53.027 dag-scheduler-event-loop INFO DAGScheduler: Got map stage job 21 (collect at utils.scala:26) with 4 output partitions
25/03/14 11:14:53.027 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ShuffleMapStage 25 (collect at utils.scala:26)
25/03/14 11:14:53.027 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:53.027 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:53.028 dag-scheduler-event-loop INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[103] at collect at utils.scala:26), which has no missing parents
25/03/14 11:14:53.030 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 24.4 KiB, free 898.5 MiB)
25/03/14 11:14:53.032 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.6 KiB, free 898.5 MiB)
25/03/14 11:14:53.032 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53646 (size: 10.6 KiB, free: 900.0 MiB)
25/03/14 11:14:53.033 dag-scheduler-event-loop INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:53.033 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[103] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:14:53.033 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks resource profile 0
25/03/14 11:14:53.034 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 44) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.034 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 45) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.034 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 46) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.034 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 47) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4950 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.034 Executor task launch worker for task 2.0 in stage 25.0 (TID 46) INFO Executor: Running task 2.0 in stage 25.0 (TID 46)
25/03/14 11:14:53.034 Executor task launch worker for task 3.0 in stage 25.0 (TID 47) INFO Executor: Running task 3.0 in stage 25.0 (TID 47)
25/03/14 11:14:53.034 Executor task launch worker for task 1.0 in stage 25.0 (TID 45) INFO Executor: Running task 1.0 in stage 25.0 (TID 45)
25/03/14 11:14:53.034 Executor task launch worker for task 0.0 in stage 25.0 (TID 44) INFO Executor: Running task 0.0 in stage 25.0 (TID 44)
25/03/14 11:14:53.036 Executor task launch worker for task 1.0 in stage 25.0 (TID 45) INFO BlockManager: Found block rdd_90_1 locally
25/03/14 11:14:53.036 Executor task launch worker for task 0.0 in stage 25.0 (TID 44) INFO BlockManager: Found block rdd_90_0 locally
25/03/14 11:14:53.036 Executor task launch worker for task 3.0 in stage 25.0 (TID 47) INFO BlockManager: Found block rdd_90_3 locally
25/03/14 11:14:53.036 Executor task launch worker for task 2.0 in stage 25.0 (TID 46) INFO BlockManager: Found block rdd_90_2 locally
25/03/14 11:14:53.046 Executor task launch worker for task 2.0 in stage 25.0 (TID 46) INFO Executor: Finished task 2.0 in stage 25.0 (TID 46). 2076 bytes result sent to driver
25/03/14 11:14:53.047 task-result-getter-0 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 46) in 13 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:14:53.048 Executor task launch worker for task 1.0 in stage 25.0 (TID 45) INFO Executor: Finished task 1.0 in stage 25.0 (TID 45). 2033 bytes result sent to driver
25/03/14 11:14:53.048 task-result-getter-1 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 45) in 14 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:14:53.050 Executor task launch worker for task 3.0 in stage 25.0 (TID 47) INFO Executor: Finished task 3.0 in stage 25.0 (TID 47). 2033 bytes result sent to driver
25/03/14 11:14:53.050 task-result-getter-2 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 47) in 16 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:14:53.052 Executor task launch worker for task 0.0 in stage 25.0 (TID 44) INFO Executor: Finished task 0.0 in stage 25.0 (TID 44). 2033 bytes result sent to driver
25/03/14 11:14:53.053 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 44) in 20 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:14:53.053 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
25/03/14 11:14:53.053 dag-scheduler-event-loop INFO DAGScheduler: ShuffleMapStage 25 (collect at utils.scala:26) finished in 0,025 s
25/03/14 11:14:53.053 dag-scheduler-event-loop INFO DAGScheduler: looking for newly runnable stages
25/03/14 11:14:53.053 dag-scheduler-event-loop INFO DAGScheduler: running: Set()
25/03/14 11:14:53.053 dag-scheduler-event-loop INFO DAGScheduler: waiting: Set()
25/03/14 11:14:53.053 dag-scheduler-event-loop INFO DAGScheduler: failed: Set()
25/03/14 11:14:53.067 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:14:53.067 dag-scheduler-event-loop INFO DAGScheduler: Got job 22 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:14:53.067 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:26)
25/03/14 11:14:53.067 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
25/03/14 11:14:53.067 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:53.069 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[106] at collect at utils.scala:26), which has no missing parents
25/03/14 11:14:53.070 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 11.1 KiB, free 898.5 MiB)
25/03/14 11:14:53.070 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 898.5 MiB)
25/03/14 11:14:53.071 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53646 (size: 5.5 KiB, free: 900.0 MiB)
25/03/14 11:14:53.071 dag-scheduler-event-loop INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:53.071 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[106] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:14:53.071 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
25/03/14 11:14:53.072 dispatcher-event-loop-5 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 48) (127.0.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.073 Executor task launch worker for task 0.0 in stage 27.0 (TID 48) INFO Executor: Running task 0.0 in stage 27.0 (TID 48)
25/03/14 11:14:53.077 Executor task launch worker for task 0.0 in stage 27.0 (TID 48) INFO ShuffleBlockFetcherIterator: Getting 4 (240.0 B) non-empty blocks including 4 (240.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/03/14 11:14:53.078 Executor task launch worker for task 0.0 in stage 27.0 (TID 48) INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/03/14 11:14:53.079 Executor task launch worker for task 0.0 in stage 27.0 (TID 48) INFO Executor: Finished task 0.0 in stage 27.0 (TID 48). 2570 bytes result sent to driver
25/03/14 11:14:53.080 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 48) in 8 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:14:53.080 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
25/03/14 11:14:53.080 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 27 (collect at utils.scala:26) finished in 0,011 s
25/03/14 11:14:53.080 dag-scheduler-event-loop INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:53.080 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
25/03/14 11:14:53.081 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 22 finished: collect at utils.scala:26, took 0,013566 s
25/03/14 11:14:53.184 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:14:53.185 dag-scheduler-event-loop INFO DAGScheduler: Got job 23 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:14:53.185 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:26)
25/03/14 11:14:53.185 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:53.185 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:53.186 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[108] at collect at utils.scala:26), which has no missing parents
25/03/14 11:14:53.187 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.3 KiB, free 898.5 MiB)
25/03/14 11:14:53.189 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 898.5 MiB)
25/03/14 11:14:53.190 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53646 (size: 3.7 KiB, free: 900.0 MiB)
25/03/14 11:14:53.191 dag-scheduler-event-loop INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:53.191 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[108] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:14:53.191 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
25/03/14 11:14:53.193 dispatcher-event-loop-3 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4661 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.193 Executor task launch worker for task 0.0 in stage 28.0 (TID 49) INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
25/03/14 11:14:53.196 Executor task launch worker for task 0.0 in stage 28.0 (TID 49) INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 1319 bytes result sent to driver
25/03/14 11:14:53.197 task-result-getter-1 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:14:53.197 task-result-getter-1 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
25/03/14 11:14:53.197 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 28 (collect at utils.scala:26) finished in 0,011 s
25/03/14 11:14:53.197 dag-scheduler-event-loop INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:53.197 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
25/03/14 11:14:53.197 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 23 finished: collect at utils.scala:26, took 0,013113 s
25/03/14 11:14:53.331 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:14:53.331 dag-scheduler-event-loop INFO DAGScheduler: Got job 24 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:14:53.331 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:26)
25/03/14 11:14:53.331 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:14:53.332 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:14:53.332 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[112] at collect at utils.scala:26), which has no missing parents
25/03/14 11:14:53.335 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 20.0 KiB, free 898.5 MiB)
25/03/14 11:14:53.335 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 898.4 MiB)
25/03/14 11:14:53.335 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53646 (size: 9.1 KiB, free: 900.0 MiB)
25/03/14 11:14:53.337 dag-scheduler-event-loop INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513
25/03/14 11:14:53.337 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[112] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:14:53.337 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
25/03/14 11:14:53.337 dispatcher-event-loop-7 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:14:53.338 Executor task launch worker for task 0.0 in stage 29.0 (TID 50) INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
25/03/14 11:14:53.342 Executor task launch worker for task 0.0 in stage 29.0 (TID 50) INFO BlockManager: Found block rdd_90_0 locally
25/03/14 11:14:53.368 Executor task launch worker for task 0.0 in stage 29.0 (TID 50) INFO CodeGenerator: Code generated in 19.0243 ms
25/03/14 11:14:53.391 Executor task launch worker for task 0.0 in stage 29.0 (TID 50) INFO Executor: 1 block locks were not released by task 0.0 in stage 29.0 (TID 50)
[rdd_90_0]
25/03/14 11:14:53.392 Executor task launch worker for task 0.0 in stage 29.0 (TID 50) INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1918 bytes result sent to driver
25/03/14 11:14:53.392 task-result-getter-2 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 55 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:14:53.392 task-result-getter-2 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
25/03/14 11:14:53.392 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 29 (collect at utils.scala:26) finished in 0,059 s
25/03/14 11:14:53.392 dag-scheduler-event-loop INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:14:53.392 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
25/03/14 11:14:53.393 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 24 finished: collect at utils.scala:26, took 0,062115 s
25/03/14 11:14:53.402 nioEventLoopGroup-2-2 INFO CodeGenerator: Code generated in 7.2427 ms
25/03/14 11:14:53.609 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:14:53.610 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:14:53.611 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:14:53.611 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:14:53.612 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:14:53.612 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:16:43.469 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:16:43.469 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:16:43.471 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:16:43.471 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:16:43.473 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:16:43.473 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:16:43.521 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: collect at utils.scala:26
25/03/14 11:16:43.521 dag-scheduler-event-loop INFO DAGScheduler: Got job 25 (collect at utils.scala:26) with 1 output partitions
25/03/14 11:16:43.521 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:26)
25/03/14 11:16:43.521 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:16:43.522 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:16:43.523 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[115] at collect at utils.scala:26), which has no missing parents
25/03/14 11:16:43.526 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.1 KiB, free 898.4 MiB)
25/03/14 11:16:43.526 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 898.4 MiB)
25/03/14 11:16:43.527 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53646 (size: 3.7 KiB, free: 900.0 MiB)
25/03/14 11:16:43.527 dag-scheduler-event-loop INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513
25/03/14 11:16:43.527 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[115] at collect at utils.scala:26) (first 15 tasks are for partitions Vector(0))
25/03/14 11:16:43.527 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
25/03/14 11:16:43.528 dispatcher-event-loop-2 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4657 bytes) taskResourceAssignments Map()
25/03/14 11:16:43.529 Executor task launch worker for task 0.0 in stage 30.0 (TID 51) INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
25/03/14 11:16:43.532 Executor task launch worker for task 0.0 in stage 30.0 (TID 51) INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 1299 bytes result sent to driver
25/03/14 11:16:43.533 task-result-getter-3 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 4 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:16:43.533 task-result-getter-3 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
25/03/14 11:16:43.533 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 30 (collect at utils.scala:26) finished in 0,010 s
25/03/14 11:16:43.533 dag-scheduler-event-loop INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:16:43.533 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
25/03/14 11:16:43.533 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 25 finished: collect at utils.scala:26, took 0,012005 s
25/03/14 11:16:43.609 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/03/14 11:16:43.613 nioEventLoopGroup-2-2 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
25/03/14 11:16:43.663 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:16:43.663 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1658, None)) > 0)
25/03/14 11:16:43.663 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:16:43.668 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 358.6 KiB, free 898.1 MiB)
25/03/14 11:16:43.676 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 898.0 MiB)
25/03/14 11:16:43.676 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 900.0 MiB)
25/03/14 11:16:43.678 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 34 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:16:43.678 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:16:43.684 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:16:43.684 dag-scheduler-event-loop INFO DAGScheduler: Got job 26 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
25/03/14 11:16:43.684 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 31 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:16:43.684 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:16:43.684 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:16:43.685 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[119] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:16:43.687 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 11.8 KiB, free 898.0 MiB)
25/03/14 11:16:43.687 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 898.0 MiB)
25/03/14 11:16:43.688 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53646 (size: 5.9 KiB, free: 900.0 MiB)
25/03/14 11:16:43.688 dag-scheduler-event-loop INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513
25/03/14 11:16:43.688 dag-scheduler-event-loop INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[119] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
25/03/14 11:16:43.688 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
25/03/14 11:16:43.689 dispatcher-event-loop-1 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 52) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:16:43.690 Executor task launch worker for task 0.0 in stage 31.0 (TID 52) INFO Executor: Running task 0.0 in stage 31.0 (TID 52)
25/03/14 11:16:43.691 Executor task launch worker for task 0.0 in stage 31.0 (TID 52) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:16:43.694 Executor task launch worker for task 0.0 in stage 31.0 (TID 52) INFO Executor: Finished task 0.0 in stage 31.0 (TID 52). 1501 bytes result sent to driver
25/03/14 11:16:43.695 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 52) in 6 ms on 127.0.0.1 (executor driver) (1/1)
25/03/14 11:16:43.695 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
25/03/14 11:16:43.696 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 31 (csv at NativeMethodAccessorImpl.java:0) finished in 0,011 s
25/03/14 11:16:43.696 dag-scheduler-event-loop INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:16:43.696 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
25/03/14 11:16:43.696 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 26 finished: csv at NativeMethodAccessorImpl.java:0, took 0,011824 s
25/03/14 11:16:43.701 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Pushed Filters: 
25/03/14 11:16:43.702 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Post-Scan Filters: 
25/03/14 11:16:43.702 nioEventLoopGroup-2-2 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
25/03/14 11:16:43.705 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 358.6 KiB, free 897.7 MiB)
25/03/14 11:16:43.712 nioEventLoopGroup-2-2 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 897.6 MiB)
25/03/14 11:16:43.712 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53646 (size: 34.9 KiB, free: 899.9 MiB)
25/03/14 11:16:43.713 nioEventLoopGroup-2-2 INFO SparkContext: Created broadcast 36 from csv at NativeMethodAccessorImpl.java:0
25/03/14 11:16:43.714 nioEventLoopGroup-2-2 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
25/03/14 11:16:43.724 nioEventLoopGroup-2-2 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
25/03/14 11:16:43.725 dag-scheduler-event-loop INFO DAGScheduler: Got job 27 (csv at NativeMethodAccessorImpl.java:0) with 4 output partitions
25/03/14 11:16:43.725 dag-scheduler-event-loop INFO DAGScheduler: Final stage: ResultStage 32 (csv at NativeMethodAccessorImpl.java:0)
25/03/14 11:16:43.725 dag-scheduler-event-loop INFO DAGScheduler: Parents of final stage: List()
25/03/14 11:16:43.725 dag-scheduler-event-loop INFO DAGScheduler: Missing parents: List()
25/03/14 11:16:43.725 dag-scheduler-event-loop INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[125] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
25/03/14 11:16:43.728 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 25.2 KiB, free 897.6 MiB)
25/03/14 11:16:43.729 dag-scheduler-event-loop INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 897.6 MiB)
25/03/14 11:16:43.729 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53646 (size: 12.0 KiB, free: 899.9 MiB)
25/03/14 11:16:43.729 dag-scheduler-event-loop INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513
25/03/14 11:16:43.729 dag-scheduler-event-loop INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[125] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
25/03/14 11:16:43.729 dag-scheduler-event-loop INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks resource profile 0
25/03/14 11:16:43.730 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 53) (127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:16:43.730 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 54) (127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:16:43.730 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 55) (127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:16:43.730 dispatcher-event-loop-0 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 56) (127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 4961 bytes) taskResourceAssignments Map()
25/03/14 11:16:43.731 Executor task launch worker for task 0.0 in stage 32.0 (TID 53) INFO Executor: Running task 0.0 in stage 32.0 (TID 53)
25/03/14 11:16:43.731 Executor task launch worker for task 1.0 in stage 32.0 (TID 54) INFO Executor: Running task 1.0 in stage 32.0 (TID 54)
25/03/14 11:16:43.731 Executor task launch worker for task 2.0 in stage 32.0 (TID 55) INFO Executor: Running task 2.0 in stage 32.0 (TID 55)
25/03/14 11:16:43.731 Executor task launch worker for task 3.0 in stage 32.0 (TID 56) INFO Executor: Running task 3.0 in stage 32.0 (TID 56)
25/03/14 11:16:43.734 Executor task launch worker for task 3.0 in stage 32.0 (TID 56) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 12582912-16399968, partition values: [empty row]
25/03/14 11:16:43.734 Executor task launch worker for task 1.0 in stage 32.0 (TID 54) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 4194304-8388608, partition values: [empty row]
25/03/14 11:16:43.734 Executor task launch worker for task 0.0 in stage 32.0 (TID 53) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 0-4194304, partition values: [empty row]
25/03/14 11:16:43.734 Executor task launch worker for task 2.0 in stage 32.0 (TID 55) INFO FileScanRDD: Reading File path: file:///D:/BTL_BigData1/Electronic-Sales-Data-main/Electronic-Sales-Data-main/all_data.csv, range: 8388608-12582912, partition values: [empty row]
25/03/14 11:16:43.838 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53646 in memory (size: 5.5 KiB, free: 899.9 MiB)
25/03/14 11:16:43.842 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53646 in memory (size: 3.7 KiB, free: 899.9 MiB)
25/03/14 11:16:43.844 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53646 in memory (size: 10.6 KiB, free: 899.9 MiB)
25/03/14 11:16:43.846 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53646 in memory (size: 3.7 KiB, free: 899.9 MiB)
25/03/14 11:16:43.848 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 900.0 MiB)
25/03/14 11:16:43.850 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53646 in memory (size: 5.5 KiB, free: 900.0 MiB)
25/03/14 11:16:43.852 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53646 in memory (size: 5.9 KiB, free: 900.0 MiB)
25/03/14 11:16:43.856 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53646 in memory (size: 9.1 KiB, free: 900.0 MiB)
25/03/14 11:16:43.856 Executor task launch worker for task 3.0 in stage 32.0 (TID 56) INFO Executor: Finished task 3.0 in stage 32.0 (TID 56). 1634 bytes result sent to driver
25/03/14 11:16:43.857 task-result-getter-1 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 56) in 127 ms on 127.0.0.1 (executor driver) (1/4)
25/03/14 11:16:43.860 Executor task launch worker for task 2.0 in stage 32.0 (TID 55) INFO Executor: Finished task 2.0 in stage 32.0 (TID 55). 1591 bytes result sent to driver
25/03/14 11:16:43.861 task-result-getter-2 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 55) in 131 ms on 127.0.0.1 (executor driver) (2/4)
25/03/14 11:16:43.861 Executor task launch worker for task 1.0 in stage 32.0 (TID 54) INFO Executor: Finished task 1.0 in stage 32.0 (TID 54). 1634 bytes result sent to driver
25/03/14 11:16:43.861 task-result-getter-3 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 54) in 131 ms on 127.0.0.1 (executor driver) (3/4)
25/03/14 11:16:43.865 Executor task launch worker for task 0.0 in stage 32.0 (TID 53) INFO Executor: Finished task 0.0 in stage 32.0 (TID 53). 1634 bytes result sent to driver
25/03/14 11:16:43.865 task-result-getter-0 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 53) in 135 ms on 127.0.0.1 (executor driver) (4/4)
25/03/14 11:16:43.865 task-result-getter-0 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
25/03/14 11:16:43.865 dag-scheduler-event-loop INFO DAGScheduler: ResultStage 32 (csv at NativeMethodAccessorImpl.java:0) finished in 0,139 s
25/03/14 11:16:43.865 dag-scheduler-event-loop INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
25/03/14 11:16:43.865 dag-scheduler-event-loop INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
25/03/14 11:16:43.865 nioEventLoopGroup-2-2 INFO DAGScheduler: Job 27 finished: csv at NativeMethodAccessorImpl.java:0, took 0,140827 s
25/03/14 11:16:43.890 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:16:43.890 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:16:43.891 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: default
25/03/14 11:16:43.891 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: default	
25/03/14 11:16:43.892 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_tables: db=default pat=*
25/03/14 11:16:43.892 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
25/03/14 11:16:43.964 nioEventLoopGroup-2-2 INFO HiveMetaStore: 0: get_database: all_data
25/03/14 11:16:43.964 nioEventLoopGroup-2-2 INFO audit: ugi=Dotro	ip=unknown-ip-addr	cmd=get_database: all_data	
25/03/14 11:16:43.965 nioEventLoopGroup-2-2 WARN ObjectStore: Failed to get database all_data, returning NoSuchObjectException
25/03/14 11:40:59.914 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53646 in memory (size: 12.0 KiB, free: 900.0 MiB)
25/03/14 11:40:59.917 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 900.0 MiB)
25/03/14 11:40:59.919 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53646 in memory (size: 10.6 KiB, free: 900.1 MiB)
25/03/14 11:40:59.922 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53646 in memory (size: 11.9 KiB, free: 900.1 MiB)
25/03/14 11:40:59.924 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53646 in memory (size: 34.8 KiB, free: 900.1 MiB)
25/03/14 11:40:59.928 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53646 in memory (size: 10.6 KiB, free: 900.1 MiB)
25/03/14 11:40:59.930 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53646 in memory (size: 10.6 KiB, free: 900.1 MiB)
25/03/14 11:40:59.933 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53646 in memory (size: 34.9 KiB, free: 900.2 MiB)
25/03/14 11:40:59.937 dispatcher-BlockManagerMaster INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53646 in memory (size: 34.8 KiB, free: 900.2 MiB)
25/03/14 11:40:59.954 block-manager-storage-async-thread-pool-129 INFO BlockManager: Removing RDD 17
25/03/14 11:40:59.958 block-manager-storage-async-thread-pool-133 INFO BlockManager: Removing RDD 54
